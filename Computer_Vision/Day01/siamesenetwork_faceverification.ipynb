{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohamedshouaib/iti/blob/main/Computer_Vision/Day01/siamesenetwork_faceverification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-04-02T08:35:02.563543Z",
          "iopub.status.busy": "2022-04-02T08:35:02.563198Z",
          "iopub.status.idle": "2022-04-02T08:35:08.798471Z",
          "shell.execute_reply": "2022-04-02T08:35:08.797717Z",
          "shell.execute_reply.started": "2022-04-02T08:35:02.563479Z"
        },
        "id": "E_Qf6ev236Hm",
        "outputId": "d812084b-b798-4495-9d5f-11a0efb90a6d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'iti'...\n",
            "remote: Enumerating objects: 638, done.\u001b[K\n",
            "remote: Counting objects: 100% (423/423), done.\u001b[K\n",
            "remote: Compressing objects: 100% (414/414), done.\u001b[K\n",
            "remote: Total 638 (delta 73), reused 0 (delta 0), pack-reused 215 (from 1)\u001b[K\n",
            "Receiving objects: 100% (638/638), 26.68 MiB | 8.30 MiB/s, done.\n",
            "Resolving deltas: 100% (145/145), done.\n",
            "Updating files: 100% (294/294), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/mohamedshouaib/iti.git\n",
        "!cd iti/Computer_Vision/Day01/Siamese"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import csv\n",
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "from itertools import combinations\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
        "from tensorflow.keras import layers, models, backend as K\n",
        "\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "tf.__version__, np.__version__"
      ],
      "metadata": {
        "id": "2_U5_fzuAD0b",
        "outputId": "92a87f29-8215-4a7f-9f0f-1837de104b74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('2.18.0', '2.0.2')"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(base_path=\"iti/Computer_Vision/Day01/Siamese\"):\n",
        "    data = {'train': {}, 'test': {}}\n",
        "\n",
        "    for person in os.listdir(base_path):\n",
        "        person_path = os.path.join(base_path, person)\n",
        "        if not os.path.isdir(person_path):\n",
        "            continue\n",
        "\n",
        "        for split in ['Train', 'Test']:\n",
        "            split_path = os.path.join(person_path, split)\n",
        "            if not os.path.exists(split_path):\n",
        "                print(f\"Missing {split} folder for {person}\")\n",
        "                continue\n",
        "\n",
        "            # Find ANY CSV file\n",
        "            csv_files = [f for f in os.listdir(split_path) if f.endswith('.csv')]\n",
        "            if not csv_files:\n",
        "                print(f\"No CSV found in {split_path}\")\n",
        "                continue\n",
        "\n",
        "            csv_path = os.path.join(split_path, csv_files[0])\n",
        "\n",
        "            genuine = []\n",
        "            forged = []\n",
        "\n",
        "            with open(csv_path, 'r') as f:\n",
        "                # Try different delimiters and column names\n",
        "                try:\n",
        "                    reader = csv.DictReader(f)\n",
        "                    row = next(reader)  # Peek first row\n",
        "\n",
        "                    # Detect column names\n",
        "                    img_col = None\n",
        "                    label_col = None\n",
        "\n",
        "                    for col in row.keys():\n",
        "                        col_lower = col.lower()\n",
        "                        if 'image' in col_lower or 'name' in col_lower:\n",
        "                            img_col = col\n",
        "                        elif 'label' in col_lower or 'class' in col_lower:\n",
        "                            label_col = col\n",
        "\n",
        "                    if not img_col or not label_col:\n",
        "                        raise ValueError(\"Couldn't detect required columns\")\n",
        "\n",
        "                    # Reset reader\n",
        "                    f.seek(0)\n",
        "                    next(reader)  # Skip header\n",
        "\n",
        "                    for row in reader:\n",
        "                        img_name = row[img_col].strip()\n",
        "                        img_path = os.path.join(split_path, img_name)\n",
        "\n",
        "                        if not os.path.exists(img_path):\n",
        "                            print(f\"Missing image: {img_path}\")\n",
        "                            continue\n",
        "\n",
        "                        label = row[label_col].strip().lower()\n",
        "                        if label == 'real' or label == 'genuine':\n",
        "                            genuine.append(img_path)\n",
        "                        elif label == 'forged' or label == 'fake':\n",
        "                            forged.append(img_path)\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"Error reading {csv_path}: {str(e)}\")\n",
        "                    continue\n",
        "\n",
        "            if genuine or forged:  # Only add if we found data\n",
        "                data[split.lower()][person] = {\n",
        "                    'genuine': genuine,\n",
        "                    'forged': forged\n",
        "                }\n",
        "\n",
        "    return data['train'], data['test']\n",
        "\n",
        "# Test with debug info\n",
        "print(\"Checking folder structure...\")\n",
        "base_path = \"iti/Computer_Vision/Day01/Siamese\"\n",
        "print(f\"Root contents: {os.listdir(base_path)}\")\n",
        "sample_person = os.listdir(base_path)[0]\n",
        "print(f\"Sample person contents: {os.listdir(os.path.join(base_path, sample_person))}\")\n",
        "\n",
        "train_data, test_data = load_dataset(base_path)\n",
        "\n",
        "print(\"\\nLoaded successfully!\")\n",
        "print(f\"Persons in train: {list(train_data.keys())}\")\n",
        "print(f\"Persons in test: {list(test_data.keys())}\")"
      ],
      "metadata": {
        "id": "e47yhiSxIHIl",
        "outputId": "1b1c9cb3-557f-4da0-a8f2-366055163c9b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking folder structure...\n",
            "Root contents: ['personA', 'personD', 'personB', 'personC', 'personE']\n",
            "Sample person contents: ['Train', 'Test']\n",
            "\n",
            "Loaded successfully!\n",
            "Persons in train: ['personA', 'personD', 'personB', 'personC', 'personE']\n",
            "Persons in test: ['personA', 'personD', 'personB', 'personC', 'personE']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_triplets(data_dict, split='train'):\n",
        "    triplets = []\n",
        "    persons = list(data_dict[split].keys())\n",
        "\n",
        "    for person in persons:\n",
        "        genuine = data_dict[split][person]['genuine']\n",
        "        forged = data_dict[split][person]['forged']\n",
        "\n",
        "        # Generate all possible genuine pairs (anchor, positive)\n",
        "        for i in range(len(genuine)):\n",
        "            for j in range(i+1, len(genuine)):\n",
        "                anchor = genuine[i]\n",
        "                positive = genuine[j]\n",
        "\n",
        "                # Pair with ALL forged signatures\n",
        "                for neg in forged:\n",
        "                    triplets.append((anchor, positive, neg))\n",
        "\n",
        "                # # Also pair with genuine from DIFFERENT person (optional)\n",
        "                # other_persons = [p for p in persons if p != person]\n",
        "                # if other_persons:\n",
        "                #     other_person = random.choice(other_persons)\n",
        "                #     other_genuine = data_dict[split][other_person]['genuine']\n",
        "                #     if other_genuine:\n",
        "                #         triplets.append((anchor, positive, random.choice(other_genuine)))\n",
        "\n",
        "    return triplets"
      ],
      "metadata": {
        "id": "7-Dk4UXBcZno"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate triplets\n",
        "train_triplets = generate_triplets({'train': train_data, 'test': test_data}, split='train')\n",
        "test_triplets = generate_triplets({'train': train_data, 'test': test_data}, split='test')"
      ],
      "metadata": {
        "id": "h5_hTUtMn1Pe"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the actual dimensions of your images\n",
        "sample_path = train_triplets[0][0]  # First anchor path\n",
        "sample_img = cv2.imread(sample_path, cv2.IMREAD_GRAYSCALE)\n",
        "true_height, true_width = sample_img.shape\n",
        "print(f\"Actual image dimensions: {true_height}x{true_width}\")\n",
        "\n",
        "# Update your input shape\n",
        "input_shape = (true_height, true_width, 1)"
      ],
      "metadata": {
        "id": "uW9yOXJ8nmYn",
        "outputId": "a4b792bc-e82e-4368-cb3c-6e796e7a9922",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual image dimensions: 312x342\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_triplet_images(triplet, img_size=(150, 150)):\n",
        "    def load_image(path):\n",
        "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "        if img is None:\n",
        "            raise ValueError(f\"Failed to load image: {path}\")\n",
        "        img = cv2.resize(img, img_size)\n",
        "        return img.astype(np.float32) / 255.0  # Normalize to [0,1]\n",
        "\n",
        "    anchor = load_image(triplet[0])\n",
        "    positive = load_image(triplet[1])\n",
        "    negative = load_image(triplet[2])\n",
        "\n",
        "    return anchor, positive, negative"
      ],
      "metadata": {
        "id": "tOEa4Tm_IHQg"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Usage Example\n",
        "train_data, test_data = load_dataset(\"iti/Computer_Vision/Day01/Siamese\")"
      ],
      "metadata": {
        "id": "YVh3zCDpSph3"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_triplet(triplet):\n",
        "    try:\n",
        "        anchor, positive, negative = load_triplet_images(triplet)\n",
        "\n",
        "        # Convert to 8-bit for display (if normalized to [0,1])\n",
        "        if anchor.max() <= 1.0:\n",
        "            anchor = (anchor * 255).astype(np.uint8)\n",
        "            positive = (positive * 255).astype(np.uint8)\n",
        "            negative = (negative * 255).astype(np.uint8)\n",
        "\n",
        "        # Create a combined display image\n",
        "        h, w = anchor.shape\n",
        "        separator = np.ones((h, 5), dtype=np.uint8) * 255  # White separator\n",
        "        combined = np.hstack([anchor, separator, positive, separator, negative])\n",
        "\n",
        "        # Add labels\n",
        "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "        cv2.putText(combined, 'Anchor', (5, 20), font, 0.5, 255, 1)\n",
        "        cv2.putText(combined, 'Positive', (w+10, 20), font, 0.5, 255, 1)\n",
        "        cv2.putText(combined, 'Negative', (2*w+15, 20), font, 0.5, 255, 1)\n",
        "\n",
        "        # Display (use cv2_imshow in Colab, cv2.imshow otherwise)\n",
        "        try:\n",
        "            from google.colab.patches import cv2_imshow\n",
        "            cv2_imshow(combined)\n",
        "        except:\n",
        "            cv2.imshow('Triplet', combined)\n",
        "            cv2.waitKey(0)\n",
        "            cv2.destroyAllWindows()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error displaying triplet: {e}\")\n",
        "        print(f\"Triplet paths: {triplet}\")"
      ],
      "metadata": {
        "id": "y2prKGo9Yohl"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Generated {len(train_triplets)} train triplets\")\n",
        "print(f\"Generated {len(test_triplets)} test triplets\")\n",
        "show_triplet(train_triplets[0])  # Display first training triplet"
      ],
      "metadata": {
        "id": "FtWMpSBvIHXx",
        "outputId": "d4562746-2133-424a-a1a8-a16c521d0dea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated 19000 train triplets\n",
            "Generated 120 test triplets\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=460x150>"
            ],
            "image/png": "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\n",
            "image/jpeg": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Embedding Network Architecture\n",
        "def create_embedding_network(input_shape):\n",
        "    \"\"\"Creates the shared weights network for signature embeddings\"\"\"\n",
        "    model = models.Sequential([\n",
        "        # Convolutional Base\n",
        "        layers.Conv2D(32, (5,5), activation='relu', input_shape=input_shape),\n",
        "        layers.MaxPooling2D((2,2)),\n",
        "        layers.BatchNormalization(),\n",
        "\n",
        "        layers.Conv2D(64, (3,3), activation='relu'),\n",
        "        layers.MaxPooling2D((2,2)),\n",
        "        layers.BatchNormalization(),\n",
        "\n",
        "        layers.Conv2D(128, (3,3), activation='relu'),\n",
        "        layers.MaxPooling2D((2,2)),\n",
        "        layers.BatchNormalization(),\n",
        "\n",
        "        # Dense Head\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(256, activation='relu'),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Dense(128, activation=None),  # No activation for embedding space\n",
        "        layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1))  # L2 normalize embeddings\n",
        "    ])\n",
        "    return model"
      ],
      "metadata": {
        "id": "-un6c44BBt6Z"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Triplet Loss Function\n",
        "class TripletLoss(layers.Layer):\n",
        "    def __init__(self, margin=0.2, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.margin = margin\n",
        "\n",
        "    def call(self, inputs):\n",
        "        anchor, positive, negative = inputs\n",
        "        pos_dist = tf.reduce_sum(tf.square(anchor - positive), axis=-1)\n",
        "        neg_dist = tf.reduce_sum(tf.square(anchor - negative), axis=-1)\n",
        "        return tf.maximum(pos_dist - neg_dist + self.margin, 0.0)\n",
        "\n",
        "    def get_config(self):\n",
        "        return {'margin': self.margin}"
      ],
      "metadata": {
        "id": "as2ZOMIdBt9I"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Data Generator (Optimized Version)\n",
        "class SignatureTripletGenerator(tf.keras.utils.Sequence):\n",
        "    def __init__(self, triplets, batch_size=32, img_size=(150,150), augment=False):\n",
        "        self.triplets = triplets\n",
        "        self.batch_size = batch_size\n",
        "        self.img_size = img_size\n",
        "        self.augment = augment\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.triplets) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        batch = self.triplets[idx*self.batch_size : (idx+1)*self.batch_size]\n",
        "\n",
        "        anchors = np.zeros((len(batch), *self.img_size, 1))\n",
        "        positives = np.zeros((len(batch), *self.img_size, 1))\n",
        "        negatives = np.zeros((len(batch), *self.img_size, 1))\n",
        "\n",
        "        for i, (a_path, p_path, n_path) in enumerate(batch):\n",
        "            # Load images with error handling\n",
        "            anchors[i] = self._load_image(a_path)\n",
        "            positives[i] = self._load_image(p_path)\n",
        "            negatives[i] = self._load_image(n_path)\n",
        "\n",
        "        return [anchors, positives, negatives], np.zeros(len(batch))\n",
        "\n",
        "    def _load_image(self, path):\n",
        "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "        if img is None:\n",
        "            raise ValueError(f\"Failed to load image: {path}\")\n",
        "\n",
        "        # Resize to target dimensions\n",
        "        img = cv2.resize(img, self.img_size)\n",
        "\n",
        "        # Data augmentation\n",
        "        if self.augment and np.random.rand() > 0.5:\n",
        "            img = cv2.flip(img, 1)  # Horizontal flip\n",
        "            if np.random.rand() > 0.5:\n",
        "                angle = np.random.uniform(-10, 10)\n",
        "                M = cv2.getRotationMatrix2D((self.img_size[0]//2, self.img_size[1]//2), angle, 1)\n",
        "                img = cv2.warpAffine(img, M, self.img_size)\n",
        "\n",
        "        return np.expand_dims(img, axis=-1) / 255.0  # Add channel and normalize\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        \"\"\"Shuffle triplets after each epoch\"\"\"\n",
        "        np.random.shuffle(self.triplets)"
      ],
      "metadata": {
        "id": "Uh7Y23LUBuAL"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Complete Siamese Model\n",
        "def build_siamese_model(input_shape):\n",
        "    # Input layers\n",
        "    anchor_input = layers.Input(input_shape, name='anchor_input')\n",
        "    positive_input = layers.Input(input_shape, name='positive_input')\n",
        "    negative_input = layers.Input(input_shape, name='negative_input')\n",
        "\n",
        "    # Shared embedding network\n",
        "    embedding_network = create_embedding_network(input_shape)\n",
        "\n",
        "    # Generate embeddings\n",
        "    anchor_embedding = embedding_network(anchor_input)\n",
        "    positive_embedding = embedding_network(positive_input)\n",
        "    negative_embedding = embedding_network(negative_input)\n",
        "\n",
        "    # Calculate triplet loss\n",
        "    loss_layer = TripletLoss(margin=0.2, name='triplet_loss')\n",
        "    loss = loss_layer([anchor_embedding, positive_embedding, negative_embedding])\n",
        "\n",
        "    # Connect inputs and outputs\n",
        "    model = models.Model(\n",
        "        inputs=[anchor_input, positive_input, negative_input],\n",
        "        outputs=loss\n",
        "    )\n",
        "\n",
        "    return model, embedding_network"
      ],
      "metadata": {
        "id": "EKsGHhCABuDV"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Model Training Setup\n",
        "# Get actual image dimensions from your data\n",
        "input_shape = (true_height, true_width, 1)\n",
        "\n",
        "# Build model\n",
        "siamese_model, embedding_model = build_siamese_model(input_shape)\n",
        "\n",
        "# Custom compile with dummy optimizer (loss is computed in model)\n",
        "siamese_model.compile(optimizer=tf.keras.optimizers.Adam(0.0001))\n",
        "\n",
        "# Create data generators\n",
        "train_generator = SignatureTripletGenerator(\n",
        "    train_triplets,\n",
        "    batch_size=32,\n",
        "    img_size=(true_width, true_height),  # OpenCV uses (width, height)\n",
        "    augment=True\n",
        ")\n",
        "\n",
        "test_generator = SignatureTripletGenerator(\n",
        "    test_triplets,\n",
        "    batch_size=32,\n",
        "    img_size=(true_width, true_height)\n",
        ")"
      ],
      "metadata": {
        "id": "QVTx_7kfBuGM"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Training Callbacks\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True),\n",
        "    tf.keras.callbacks.ModelCheckpoint(\n",
        "        'siamese_best.h5',\n",
        "        save_best_only=True,\n",
        "        save_weights_only=True\n",
        "    ),\n",
        "    tf.keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=3)\n",
        "]"
      ],
      "metadata": {
        "id": "KBDUN15uBuJI",
        "outputId": "3f130ec0-7037-4e37-88cd-c841a1208797",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        }
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "When using `save_weights_only=True` in `ModelCheckpoint`, the filepath provided must end in `.weights.h5` (Keras weights format). Received: filepath=siamese_best.h5",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-103-420ec469dbe3>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m callbacks = [\n\u001b[1;32m      3\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestore_best_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     tf.keras.callbacks.ModelCheckpoint(\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0;34m'siamese_best.h5'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0msave_best_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/callbacks/model_checkpoint.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filepath, monitor, verbose, save_best_only, save_weights_only, mode, save_freq, initial_value_threshold)\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msave_weights_only\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".weights.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m    185\u001b[0m                     \u001b[0;34m\"When using `save_weights_only=True` in `ModelCheckpoint`\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m                     \u001b[0;34m\", the filepath provided must end in `.weights.h5` \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: When using `save_weights_only=True` in `ModelCheckpoint`, the filepath provided must end in `.weights.h5` (Keras weights format). Received: filepath=siamese_best.h5"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Train the Model\n",
        "history = siamese_model.fit(\n",
        "    train_generator,\n",
        "    validation_data=test_generator,\n",
        "    epochs=50,\n",
        "    callbacks=callbacks\n",
        ")"
      ],
      "metadata": {
        "id": "uNKyAXeyBuLS"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. Save the Embedding Model\n",
        "embedding_model.save('signature_embedder.h5')"
      ],
      "metadata": {
        "id": "qH_FpMcRjL7I"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MskKE_O2jMDi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v_jVparLrpRD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Pbl6AIncrpT9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J1UZcCQcrpWw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XJIxHevHrpZ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pGu8SjgFrpco"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OYd8f0e3rpfp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1-Opt9pCrphV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def verify_signatures(anchor_path, test_path, threshold=0.5):\n",
        "    # Load models\n",
        "    embedding_model = tf.keras.models.load_model('signature_embedding.h5')\n",
        "\n",
        "    # Preprocess images\n",
        "    def preprocess(path):\n",
        "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "        img = cv2.resize(img, (150, 150)).reshape(1, 150, 150, 1)/255.0\n",
        "        return img\n",
        "\n",
        "    # Get embeddings\n",
        "    anchor_embed = embedding_model.predict(preprocess(anchor_path))\n",
        "    test_embed = embedding_model.predict(preprocess(test_path))\n",
        "\n",
        "    # Calculate distance\n",
        "    distance = np.sum(np.square(anchor_embed - test_embed))\n",
        "\n",
        "    # Verification decision\n",
        "    return distance < threshold, distance\n",
        "\n",
        "# Example usage\n",
        "is_genuine, dist = verify_signatures(\n",
        "    anchor_path=\"path/to/genuine_sample.png\",\n",
        "    test_path=\"path/to/test_sample.png\"\n",
        ")\n",
        "print(f\"Genuine: {is_genuine} (Distance: {dist:.4f})\")"
      ],
      "metadata": {
        "id": "uebD7FK2jMFn"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}