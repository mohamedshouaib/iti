{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohamedshouaib/iti/blob/main/Computer_Vision/Day01/siamesenetwork_faceverification3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-04-02T08:35:02.563543Z",
          "iopub.status.busy": "2022-04-02T08:35:02.563198Z",
          "iopub.status.idle": "2022-04-02T08:35:08.798471Z",
          "shell.execute_reply": "2022-04-02T08:35:08.797717Z",
          "shell.execute_reply.started": "2022-04-02T08:35:02.563479Z"
        },
        "id": "E_Qf6ev236Hm",
        "outputId": "8be514ef-556e-4610-bef3-b987360f03f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'iti' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/mohamedshouaib/iti.git\n",
        "!cd iti/Computer_Vision/Day01/Siamese"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import csv\n",
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "from itertools import combinations\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from tqdm import tqdm\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "2_U5_fzuAD0b"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(base_path=\"iti/Computer_Vision/Day01/Siamese\"):\n",
        "    data = {'train': {}, 'test': {}}\n",
        "\n",
        "    for person in os.listdir(base_path):\n",
        "        person_path = os.path.join(base_path, person)\n",
        "        if not os.path.isdir(person_path):\n",
        "            continue\n",
        "\n",
        "        for split in ['Train', 'Test']:\n",
        "            split_path = os.path.join(person_path, split)\n",
        "            if not os.path.exists(split_path):\n",
        "                print(f\"Missing {split} folder for {person}\")\n",
        "                continue\n",
        "\n",
        "            # Find ANY CSV file\n",
        "            csv_files = [f for f in os.listdir(split_path) if f.endswith('.csv')]\n",
        "            if not csv_files:\n",
        "                print(f\"No CSV found in {split_path}\")\n",
        "                continue\n",
        "\n",
        "            csv_path = os.path.join(split_path, csv_files[0])\n",
        "\n",
        "            genuine = []\n",
        "            forged = []\n",
        "\n",
        "            with open(csv_path, 'r') as f:\n",
        "                # Try different delimiters and column names\n",
        "                try:\n",
        "                    reader = csv.DictReader(f)\n",
        "                    row = next(reader)  # Peek first row\n",
        "\n",
        "                    # Detect column names\n",
        "                    img_col = None\n",
        "                    label_col = None\n",
        "\n",
        "                    for col in row.keys():\n",
        "                        col_lower = col.lower()\n",
        "                        if 'image' in col_lower or 'name' in col_lower:\n",
        "                            img_col = col\n",
        "                        elif 'label' in col_lower or 'class' in col_lower:\n",
        "                            label_col = col\n",
        "\n",
        "                    if not img_col or not label_col:\n",
        "                        raise ValueError(\"Couldn't detect required columns\")\n",
        "\n",
        "                    # Reset reader\n",
        "                    f.seek(0)\n",
        "                    next(reader)  # Skip header\n",
        "\n",
        "                    for row in reader:\n",
        "                        img_name = row[img_col].strip()\n",
        "                        img_path = os.path.join(split_path, img_name)\n",
        "\n",
        "                        if not os.path.exists(img_path):\n",
        "                            print(f\"Missing image: {img_path}\")\n",
        "                            continue\n",
        "\n",
        "                        label = row[label_col].strip().lower()\n",
        "                        if label == 'real' or label == 'genuine':\n",
        "                            genuine.append(img_path)\n",
        "                        elif label == 'forged' or label == 'fake':\n",
        "                            forged.append(img_path)\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"Error reading {csv_path}: {str(e)}\")\n",
        "                    continue\n",
        "\n",
        "            if genuine or forged:  # Only add if we found data\n",
        "                data[split.lower()][person] = {\n",
        "                    'genuine': genuine,\n",
        "                    'forged': forged\n",
        "                }\n",
        "\n",
        "    return data['train'], data['test']\n",
        "\n",
        "# Test with debug info\n",
        "print(\"Checking folder structure...\")\n",
        "base_path = \"iti/Computer_Vision/Day01/Siamese\"\n",
        "print(f\"Root contents: {os.listdir(base_path)}\")\n",
        "sample_person = os.listdir(base_path)[0]\n",
        "print(f\"Sample person contents: {os.listdir(os.path.join(base_path, sample_person))}\")\n",
        "\n",
        "train_data, test_data = load_dataset(base_path)\n",
        "\n",
        "print(\"\\nLoaded successfully!\")\n",
        "print(f\"Persons in train: {list(train_data.keys())}\")\n",
        "print(f\"Persons in test: {list(test_data.keys())}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e47yhiSxIHIl",
        "outputId": "9c7537c7-5cc5-48a2-da48-1bedb5f9e842"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking folder structure...\n",
            "Root contents: ['personE', 'personA', 'personB', 'personD', 'personC']\n",
            "Sample person contents: ['Test', 'Train']\n",
            "\n",
            "Loaded successfully!\n",
            "Persons in train: ['personE', 'personA', 'personB', 'personD', 'personC']\n",
            "Persons in test: ['personE', 'personA', 'personB', 'personD', 'personC']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_triplets(data_dict, split='train'):\n",
        "    triplets = []\n",
        "    persons = list(data_dict[split].keys())\n",
        "\n",
        "    for person in persons:\n",
        "        genuine = data_dict[split][person]['genuine']\n",
        "        forged = data_dict[split][person]['forged']\n",
        "\n",
        "        # Generate all possible genuine pairs (anchor, positive)\n",
        "        for i in range(len(genuine)):\n",
        "            for j in range(i+1, len(genuine)):\n",
        "                anchor = genuine[i]\n",
        "                positive = genuine[j]\n",
        "\n",
        "                # Pair with ALL forged signatures\n",
        "                for neg in forged:\n",
        "                    triplets.append((anchor, positive, neg))\n",
        "\n",
        "                # # Also pair with genuine from DIFFERENT person (optional)\n",
        "                # other_persons = [p for p in persons if p != person]\n",
        "                # if other_persons:\n",
        "                #     other_person = random.choice(other_persons)\n",
        "                #     other_genuine = data_dict[split][other_person]['genuine']\n",
        "                #     if other_genuine:\n",
        "                #         triplets.append((anchor, positive, random.choice(other_genuine)))\n",
        "\n",
        "    return triplets"
      ],
      "metadata": {
        "id": "7-Dk4UXBcZno"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate triplets\n",
        "train_triplets = generate_triplets({'train': train_data, 'test': test_data}, split='train')\n",
        "test_triplets = generate_triplets({'train': train_data, 'test': test_data}, split='test')"
      ],
      "metadata": {
        "id": "h5_hTUtMn1Pe"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the actual dimensions of your images\n",
        "sample_path = train_triplets[0][0]  # First anchor path\n",
        "sample_img = cv2.imread(sample_path, cv2.IMREAD_GRAYSCALE)\n",
        "true_height, true_width = sample_img.shape\n",
        "print(f\"Actual image dimensions: {true_height}x{true_width}\")\n",
        "\n",
        "# Update your input shape\n",
        "input_shape = (true_height, true_width, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uW9yOXJ8nmYn",
        "outputId": "5a4e0e77-ae6f-4ca6-9799-17e7e457d7f8"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual image dimensions: 403x420\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_triplet_images(triplet, img_size=(150, 150)):\n",
        "    def load_image(path):\n",
        "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "        if img is None:\n",
        "            raise ValueError(f\"Failed to load image: {path}\")\n",
        "        img = cv2.resize(img, img_size)\n",
        "        return img.astype(np.float32) / 255.0  # Normalize to [0,1]\n",
        "\n",
        "    anchor = load_image(triplet[0])\n",
        "    positive = load_image(triplet[1])\n",
        "    negative = load_image(triplet[2])\n",
        "\n",
        "    return anchor, positive, negative"
      ],
      "metadata": {
        "id": "tOEa4Tm_IHQg"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Usage Example\n",
        "train_data, test_data = load_dataset(\"iti/Computer_Vision/Day01/Siamese\")"
      ],
      "metadata": {
        "id": "YVh3zCDpSph3"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_triplet(triplet):\n",
        "    try:\n",
        "        anchor, positive, negative = load_triplet_images(triplet)\n",
        "\n",
        "        # Convert to 8-bit for display (if normalized to [0,1])\n",
        "        if anchor.max() <= 1.0:\n",
        "            anchor = (anchor * 255).astype(np.uint8)\n",
        "            positive = (positive * 255).astype(np.uint8)\n",
        "            negative = (negative * 255).astype(np.uint8)\n",
        "\n",
        "        # Create a combined display image\n",
        "        h, w = anchor.shape\n",
        "        separator = np.ones((h, 5), dtype=np.uint8) * 255  # White separator\n",
        "        combined = np.hstack([anchor, separator, positive, separator, negative])\n",
        "\n",
        "        # Add labels\n",
        "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "        cv2.putText(combined, 'Anchor', (5, 20), font, 0.5, 255, 1)\n",
        "        cv2.putText(combined, 'Positive', (w+10, 20), font, 0.5, 255, 1)\n",
        "        cv2.putText(combined, 'Negative', (2*w+15, 20), font, 0.5, 255, 1)\n",
        "\n",
        "        # Display (use cv2_imshow in Colab, cv2.imshow otherwise)\n",
        "        try:\n",
        "            from google.colab.patches import cv2_imshow\n",
        "            cv2_imshow(combined)\n",
        "        except:\n",
        "            cv2.imshow('Triplet', combined)\n",
        "            cv2.waitKey(0)\n",
        "            cv2.destroyAllWindows()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error displaying triplet: {e}\")\n",
        "        print(f\"Triplet paths: {triplet}\")"
      ],
      "metadata": {
        "id": "y2prKGo9Yohl"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Generated {len(train_triplets)} train triplets\")\n",
        "print(f\"Generated {len(test_triplets)} test triplets\")\n",
        "show_triplet(train_triplets[0])  # Display first training triplet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "FtWMpSBvIHXx",
        "outputId": "8b66168c-9bc8-4b4e-b4f0-c96e77e741e8"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated 19000 train triplets\n",
            "Generated 120 test triplets\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=460x150>"
            ],
            "image/png": "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\n",
            "image/jpeg": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SiameseNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SiameseNetwork, self).__init__()\n",
        "\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=5),  # output: (32, 146, 146)\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),                  # output: (32, 73, 73)\n",
        "\n",
        "            nn.Conv2d(32, 64, kernel_size=5), # output: (64, 69, 69)\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),                  # output: (64, 34, 34)\n",
        "        )\n",
        "\n",
        "        # Dynamically determine the output size after CNN layers\n",
        "        with torch.no_grad():\n",
        "            dummy_input = torch.zeros(1, 1, 150, 150)  # (batch, channel, height, width)\n",
        "            dummy_output = self.cnn(dummy_input)\n",
        "            self.flattened_size = dummy_output.view(1, -1).shape[1]\n",
        "            print(f\"[INFO] Flattened feature size: {self.flattened_size}\")\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(self.flattened_size, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 128)\n",
        "        )\n",
        "\n",
        "    def forward_once(self, x):\n",
        "        x = self.cnn(x)\n",
        "        x = x.view(x.size(0), -1)  # Flatten\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "    def forward(self, anchor, positive, negative):\n",
        "        out_anchor = self.forward_once(anchor)\n",
        "        out_positive = self.forward_once(positive)\n",
        "        out_negative = self.forward_once(negative)\n",
        "        return out_anchor, out_positive, out_negative\n"
      ],
      "metadata": {
        "id": "EGswz_0douM8"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TripletLoss(nn.Module):\n",
        "    def __init__(self, margin=1.0):\n",
        "        super(TripletLoss, self).__init__()\n",
        "        self.margin = margin\n",
        "\n",
        "    def forward(self, anchor, positive, negative):\n",
        "        distance_pos = F.pairwise_distance(anchor, positive)\n",
        "        distance_neg = F.pairwise_distance(anchor, negative)\n",
        "        losses = F.relu(distance_pos - distance_neg + self.margin)\n",
        "        return losses.mean()\n"
      ],
      "metadata": {
        "id": "c2_HzaSxouPx"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TripletDataset(Dataset):\n",
        "    def __init__(self, triplets, img_size=(150, 150)):\n",
        "        self.triplets = triplets\n",
        "        self.img_size = img_size\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.triplets)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        a, p, n = self.triplets[idx]\n",
        "        anchor, positive, negative = load_triplet_images((a, p, n), self.img_size)\n",
        "\n",
        "        # Add channel dim\n",
        "        anchor = torch.tensor(anchor).unsqueeze(0)\n",
        "        positive = torch.tensor(positive).unsqueeze(0)\n",
        "        negative = torch.tensor(negative).unsqueeze(0)\n",
        "\n",
        "        return anchor, positive, negative"
      ],
      "metadata": {
        "id": "z86GLa5xouTG"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = SiameseNetwork().to(device)\n",
        "loss_fn = TripletLoss(margin=1.0)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
        "\n",
        "train_dataset = TripletDataset(train_triplets)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# Train\n",
        "num_epochs = 5\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "\n",
        "    for anchor, positive, negative in loop:\n",
        "        anchor, positive, negative = anchor.to(device), positive.to(device), negative.to(device)\n",
        "\n",
        "        out_a, out_p, out_n = model(anchor, positive, negative)\n",
        "        loss = loss_fn(out_a, out_p, out_n)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        loop.set_postfix(loss=loss.item())\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {epoch_loss/len(train_loader)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "ak6K1vOhT1Ab",
        "outputId": "39da0831-951b-414b-ec1b-2eb23e0bbd87"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Flattened feature size: 73984\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/5: 100%|██████████| 594/594 [03:05<00:00,  3.20it/s, loss=0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 3.2211607488417866\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/5: 100%|██████████| 594/594 [03:05<00:00,  3.20it/s, loss=0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2, Loss: 5.710701977765119\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/5:  12%|█▏        | 69/594 [00:21<02:47,  3.14it/s, loss=0]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-73-1e16768b9f31>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mloop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"Epoch {epoch+1}/{num_epochs}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0manchor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0manchor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manchor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-72-01f92e76e9d6>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtriplets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0manchor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_triplet_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# Add channel dim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-66-82c0d9bfb9b8>\u001b[0m in \u001b[0;36mload_triplet_images\u001b[0;34m(triplet, img_size)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0manchor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtriplet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mpositive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtriplet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mnegative\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtriplet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-66-82c0d9bfb9b8>\u001b[0m in \u001b[0;36mload_image\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_triplet_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtriplet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m150\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMREAD_GRAYSCALE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Failed to load image: {path}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, test_triplets):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for triplet in test_triplets:\n",
        "            a, p, n = load_triplet_images(triplet)\n",
        "            a = torch.tensor(a).unsqueeze(0).unsqueeze(0).to(device)\n",
        "            p = torch.tensor(p).unsqueeze(0).unsqueeze(0).to(device)\n",
        "            n = torch.tensor(n).unsqueeze(0).unsqueeze(0).to(device)\n",
        "\n",
        "            out_a, out_p = model.forward_once(a), model.forward_once(p)\n",
        "            out_n = model.forward_once(n)\n",
        "\n",
        "            d_ap = F.pairwise_distance(out_a, out_p)\n",
        "            d_an = F.pairwise_distance(out_a, out_n)\n",
        "\n",
        "            if d_ap.item() < d_an.item():\n",
        "                correct += 1\n",
        "            total += 1\n",
        "\n",
        "    print(f\"Accuracy on test set: {correct / total:.2f}\")\n"
      ],
      "metadata": {
        "id": "Xt-h10kqouVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model on the test triplets\n",
        "evaluate_model(model, test_triplets)"
      ],
      "metadata": {
        "id": "cuIgyx1ERk4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'siamese_signature_model.pth')\n",
        "\n",
        "# To load later\n",
        "# model.load_state_dict(torch.load('siamese_signature_model.pth'))\n",
        "# model.eval()\n"
      ],
      "metadata": {
        "id": "_AxePUUmouXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_signature_pair(img_path1, img_path2, model, threshold=1.5):\n",
        "    model.eval()\n",
        "    img1, img2 = load_triplet_images((img_path1, img_path2, img_path2))[:2]  # ignore negative\n",
        "\n",
        "    img1 = torch.tensor(img1).unsqueeze(0).unsqueeze(0).to(device)\n",
        "    img2 = torch.tensor(img2).unsqueeze(0).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        out1 = model.forward_once(img1)\n",
        "        out2 = model.forward_once(img2)\n",
        "\n",
        "    distance = F.pairwise_distance(out1, out2).item()\n",
        "    print(f\"Distance: {distance:.4f}\")\n",
        "    return distance < threshold  # True if similar\n"
      ],
      "metadata": {
        "id": "YLU0DlhOousF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example real vs. real (should return True if genuine match)\n",
        "img_path1 = 'iti/Computer_Vision/Day01/Siamese/personA/Test/personA_29.png'\n",
        "img_path2 = 'iti/Computer_Vision/Day01/Siamese/personA/Test/personA_13.png'\n",
        "\n",
        "# Example real vs. forged (should return False if forged)\n",
        "img_path3 = 'iti/Computer_Vision/Day01/Siamese/personA/Test/personA_29.png'\n",
        "img_path4 = 'iti/Computer_Vision/Day01/Siamese/personA/Test/personA_33.png'\n",
        "\n",
        "# Test genuine match\n",
        "is_match = test_signature_pair(img_path1, img_path2, model)\n",
        "print(\"Match (real vs. real):\", is_match)\n",
        "\n",
        "# Test forged case\n",
        "is_forged = test_signature_pair(img_path3, img_path4, model)\n",
        "print(\"Match (real vs. forged):\", is_forged)"
      ],
      "metadata": {
        "id": "yUjdinFtouu3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}