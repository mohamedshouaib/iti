{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohamedshouaib/iti/blob/main/Computer_Vision/Day01/siamesenetwork_faceverification4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-04-02T08:35:02.563543Z",
          "iopub.status.busy": "2022-04-02T08:35:02.563198Z",
          "iopub.status.idle": "2022-04-02T08:35:08.798471Z",
          "shell.execute_reply": "2022-04-02T08:35:08.797717Z",
          "shell.execute_reply.started": "2022-04-02T08:35:02.563479Z"
        },
        "id": "E_Qf6ev236Hm",
        "outputId": "f85e1191-508f-4a18-f360-7e44e6692279",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'iti'...\n",
            "remote: Enumerating objects: 658, done.\u001b[K\n",
            "remote: Counting objects: 100% (443/443), done.\u001b[K\n",
            "remote: Compressing objects: 100% (434/434), done.\u001b[K\n",
            "remote: Total 658 (delta 83), reused 0 (delta 0), pack-reused 215 (from 1)\u001b[K\n",
            "Receiving objects: 100% (658/658), 26.77 MiB | 17.25 MiB/s, done.\n",
            "Resolving deltas: 100% (155/155), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/mohamedshouaib/iti.git\n",
        "!cd iti/Computer_Vision/Day01/Siamese"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import csv\n",
        "import time\n",
        "import random\n",
        "import argparse\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.autograd import Variable\n",
        "import torchvision.transforms as transforms\n",
        "from datetime import datetime\n",
        "from pytz import timezone\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "2_U5_fzuAD0b"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyper Parameters\n",
        "BATCH_SIZE = 32\n",
        "IMAGE_SIZE = (150, 150)"
      ],
      "metadata": {
        "id": "YVYbGlpaic-m"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Loading Functions (Your existing code)\n",
        "def load_dataset(base_path=\"iti/Computer_Vision/Day01/Siamese\"):\n",
        "    data = {'train': {}, 'test': {}}\n",
        "\n",
        "    for person in os.listdir(base_path):\n",
        "        person_path = os.path.join(base_path, person)\n",
        "        if not os.path.isdir(person_path):\n",
        "            continue\n",
        "\n",
        "        for split in ['Train', 'Test']:\n",
        "            split_path = os.path.join(person_path, split)\n",
        "            if not os.path.exists(split_path):\n",
        "                print(f\"Missing {split} folder for {person}\")\n",
        "                continue\n",
        "\n",
        "            csv_files = [f for f in os.listdir(split_path) if f.endswith('.csv')]\n",
        "            if not csv_files:\n",
        "                print(f\"No CSV found in {split_path}\")\n",
        "                continue\n",
        "\n",
        "            csv_path = os.path.join(split_path, csv_files[0])\n",
        "\n",
        "            genuine = []\n",
        "            forged = []\n",
        "\n",
        "            with open(csv_path, 'r') as f:\n",
        "                try:\n",
        "                    reader = csv.DictReader(f)\n",
        "                    row = next(reader)\n",
        "\n",
        "                    img_col = None\n",
        "                    label_col = None\n",
        "\n",
        "                    for col in row.keys():\n",
        "                        col_lower = col.lower()\n",
        "                        if 'image' in col_lower or 'name' in col_lower:\n",
        "                            img_col = col\n",
        "                        elif 'label' in col_lower or 'class' in col_lower:\n",
        "                            label_col = col\n",
        "\n",
        "                    if not img_col or not label_col:\n",
        "                        raise ValueError(\"Couldn't detect required columns\")\n",
        "\n",
        "                    f.seek(0)\n",
        "                    next(reader)\n",
        "\n",
        "                    for row in reader:\n",
        "                        img_name = row[img_col].strip()\n",
        "                        img_path = os.path.join(split_path, img_name)\n",
        "\n",
        "                        if not os.path.exists(img_path):\n",
        "                            print(f\"Missing image: {img_path}\")\n",
        "                            continue\n",
        "\n",
        "                        label = row[label_col].strip().lower()\n",
        "                        if label == 'real' or label == 'genuine':\n",
        "                            genuine.append(img_path)\n",
        "                        elif label == 'forged' or label == 'fake':\n",
        "                            forged.append(img_path)\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"Error reading {csv_path}: {str(e)}\")\n",
        "                    continue\n",
        "\n",
        "            if genuine or forged:\n",
        "                data[split.lower()][person] = {\n",
        "                    'genuine': genuine,\n",
        "                    'forged': forged\n",
        "                }\n",
        "\n",
        "    return data['train'], data['test']"
      ],
      "metadata": {
        "id": "e47yhiSxIHIl"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_triplets(data_dict, split='train'):\n",
        "    triplets = []\n",
        "    persons = list(data_dict[split].keys())\n",
        "\n",
        "    for person in persons:\n",
        "        genuine = data_dict[split][person]['genuine']\n",
        "        forged = data_dict[split][person]['forged']\n",
        "\n",
        "        for i in range(len(genuine)):\n",
        "            for j in range(i+1, len(genuine)):\n",
        "                anchor = genuine[i]\n",
        "                positive = genuine[j]\n",
        "\n",
        "                for neg in forged:\n",
        "                    triplets.append((anchor, positive, neg))\n",
        "\n",
        "    return triplets"
      ],
      "metadata": {
        "id": "7-Dk4UXBcZno"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom Dataset Class\n",
        "class SignatureTripletDataset(Dataset):\n",
        "    def __init__(self, triplets, transform=None):\n",
        "        self.triplets = triplets\n",
        "        self.transform = transform or transforms.Compose([\n",
        "            transforms.Resize(IMAGE_SIZE),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.5], std=[0.5])\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.triplets)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        anchor_path, positive_path, negative_path = self.triplets[idx]\n",
        "\n",
        "        anchor = Image.open(anchor_path).convert('L')\n",
        "        positive = Image.open(positive_path).convert('L')\n",
        "        negative = Image.open(negative_path).convert('L')\n",
        "\n",
        "        if self.transform:\n",
        "            anchor = self.transform(anchor)\n",
        "            positive = self.transform(positive)\n",
        "            negative = self.transform(negative)\n",
        "\n",
        "        return anchor, positive, negative"
      ],
      "metadata": {
        "id": "h5_hTUtMn1Pe"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Architecture\n",
        "class SiameseNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SiameseNetwork, self).__init__()\n",
        "\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv2d(1, 64, kernel_size=5, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Dropout(0.3),  # Added dropout\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=5, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Dropout(0.3),  # Added dropout\n",
        "\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Dropout(0.3),  # Added dropout\n",
        "\n",
        "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.Dropout(0.5),  # Higher dropout before final layers\n",
        "\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(512*18*18, 1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),  # Dropout in fully connected layer\n",
        "            nn.Linear(1024, 256)  # Smaller embedding size\n",
        "        )\n",
        "\n",
        "    def forward_once(self, x):\n",
        "        return self.cnn(x)\n",
        "\n",
        "    def forward(self, input1, input2, input3):\n",
        "        output1 = self.forward_once(input1)\n",
        "        output2 = self.forward_once(input2)\n",
        "        output3 = self.forward_once(input3)\n",
        "        return output1, output2, output3"
      ],
      "metadata": {
        "id": "uW9yOXJ8nmYn"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Triplet Loss\n",
        "class TripletLoss(nn.Module):\n",
        "    def __init__(self, margin=1.0):\n",
        "        super(TripletLoss, self).__init__()\n",
        "        self.margin = margin\n",
        "\n",
        "    def forward(self, anchor, positive, negative):\n",
        "        pos_dist = F.pairwise_distance(anchor, positive, 2)\n",
        "        neg_dist = F.pairwise_distance(anchor, negative, 2)\n",
        "        losses = F.relu(pos_dist - neg_dist + self.margin)\n",
        "        return losses.mean()"
      ],
      "metadata": {
        "id": "YVh3zCDpSph3"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(train_loader, test_loader, args):\n",
        "    model = SiameseNetwork()\n",
        "    if args.cuda:\n",
        "        model = model.cuda()\n",
        "\n",
        "    # Initialize Triplet Loss criterion with margin from args\n",
        "    criterion = TripletLoss(margin=args.margin)\n",
        "\n",
        "    # Optimizer with L2 regularization\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-4)\n",
        "\n",
        "    # Learning rate scheduler\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, mode='min', patience=2, factor=0.5, verbose=True\n",
        "    )\n",
        "\n",
        "    # Early stopping setup\n",
        "    best_val_loss = float('inf')\n",
        "    patience = 3\n",
        "    patience_counter = 0\n",
        "\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "\n",
        "    for epoch in range(args.epochs):\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        epoch_train_loss = 0.0\n",
        "\n",
        "        with tqdm(train_loader, unit=\"batch\", desc=f\"Epoch {epoch+1}/{args.epochs} [Train]\") as tepoch:\n",
        "            for anchor, positive, negative in tepoch:\n",
        "                if args.cuda:\n",
        "                    anchor, positive, negative = anchor.cuda(), positive.cuda(), negative.cuda()\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                anchor_out, pos_out, neg_out = model(anchor, positive, negative)\n",
        "                loss = criterion(anchor_out, pos_out, neg_out)\n",
        "\n",
        "                loss.backward()\n",
        "                # Gradient clipping\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "                optimizer.step()\n",
        "\n",
        "                epoch_train_loss += loss.item()\n",
        "                tepoch.set_postfix(loss=loss.item())\n",
        "\n",
        "        avg_train_loss = epoch_train_loss / len(train_loader)\n",
        "        train_losses.append(avg_train_loss)\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        epoch_val_loss = 0.0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            with tqdm(test_loader, unit=\"batch\", desc=f\"Epoch {epoch+1}/{args.epochs} [Val]\") as vepoch:\n",
        "                for anchor, positive, negative in vepoch:\n",
        "                    if args.cuda:\n",
        "                        anchor, positive, negative = anchor.cuda(), positive.cuda(), negative.cuda()\n",
        "\n",
        "                    anchor_out, pos_out, neg_out = model(anchor, positive, negative)\n",
        "                    val_loss = criterion(anchor_out, pos_out, neg_out)\n",
        "                    epoch_val_loss += val_loss.item()\n",
        "                    vepoch.set_postfix(loss=val_loss.item())\n",
        "\n",
        "        avg_val_loss = epoch_val_loss / len(test_loader)\n",
        "        val_losses.append(avg_val_loss)\n",
        "\n",
        "        # Update learning rate based on validation loss\n",
        "        scheduler.step(avg_val_loss)\n",
        "\n",
        "        # Early stopping check\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "            torch.save(model.state_dict(), 'best_model.pth')\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= patience:\n",
        "                print(f\"\\nEarly stopping triggered at epoch {epoch+1}\")\n",
        "                break\n",
        "\n",
        "        # Print epoch summary\n",
        "        print(f\"\\nEpoch {epoch+1} Summary:\")\n",
        "        print(f\"Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
        "        print(f\"Learning Rate: {optimizer.param_groups[0]['lr']:.2e}\")\n",
        "        print(f\"Best Val Loss: {best_val_loss:.4f}\")\n",
        "\n",
        "    # Plot training history\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(train_losses, label='Training Loss')\n",
        "    plt.plot(val_losses, label='Validation Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.legend()\n",
        "    plt.savefig('training_history.png')\n",
        "    plt.close()\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "y2prKGo9Yohl"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main Function\n",
        "def main():\n",
        "    # For Jupyter/Colab environment\n",
        "    class Args:\n",
        "        epochs = 5\n",
        "        margin = 1.0\n",
        "        cuda = torch.cuda.is_available()\n",
        "\n",
        "    args = Args()\n",
        "\n",
        "    # Load data\n",
        "    print(\"Loading dataset...\")\n",
        "    train_data, test_data = load_dataset()\n",
        "    print(\"Generating triplets...\")\n",
        "    train_triplets = generate_triplets({'train': train_data, 'test': test_data}, 'train')\n",
        "    test_triplets = generate_triplets({'train': train_data, 'test': test_data}, 'test')\n",
        "\n",
        "    print(f\"Training triplets: {len(train_triplets)}\")\n",
        "    print(f\"Testing triplets: {len(test_triplets)}\")\n",
        "\n",
        "    # Create datasets\n",
        "    print(\"Creating datasets...\")\n",
        "    train_dataset = SignatureTripletDataset(train_triplets)\n",
        "    test_dataset = SignatureTripletDataset(test_triplets)\n",
        "\n",
        "    # Create dataloaders\n",
        "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    # Train model\n",
        "    print(\"Starting training...\")\n",
        "    model = train_model(train_loader, test_loader, args)\n",
        "\n",
        "    # Save final model\n",
        "    torch.save(model.state_dict(), 'final_model.pth')\n",
        "    print(\"Training complete. Models saved as 'best_model.pth' and 'final_model.pth'\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FtWMpSBvIHXx",
        "outputId": "c9ce33bc-8ed5-42f3-cf9b-2972e9b79001"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading dataset...\n",
            "Generating triplets...\n",
            "Training triplets: 19000\n",
            "Testing triplets: 120\n",
            "Creating datasets...\n",
            "Starting training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n",
            "Epoch 1/5 [Train]: 100%|██████████| 594/594 [06:40<00:00,  1.48batch/s, loss=0]\n",
            "Epoch 1/5 [Val]: 100%|██████████| 4/4 [00:01<00:00,  2.67batch/s, loss=0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1 Summary:\n",
            "Train Loss: 0.0397 | Val Loss: 1.7447\n",
            "Learning Rate: 1.00e-04\n",
            "Best Val Loss: 1.7447\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/5 [Train]:  39%|███▉      | 234/594 [02:36<04:00,  1.50batch/s, loss=0]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9SaOgzWqjJPV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b1471jzukG-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QE9sLNWtkHBV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x85_Z--nkHGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j2nuTC1skHH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r0WxUkftkHJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J88E8WfMkHLo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BHrCY19XkHOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-eUULWgLkHRK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aGMj4jaCjJcI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##################"
      ],
      "metadata": {
        "id": "jCCAbWnMjJf8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyper Parameters\n",
        "BATCH_SIZE = 50"
      ],
      "metadata": {
        "id": "EGswz_0douM8"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ContrastiveLoss(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, margin=1.0):\n",
        "        super(ContrastiveLoss, self).__init__()\n",
        "        self.margin = margin\n",
        "\n",
        "    def forward(self, input1, input2, y):\n",
        "        diff = input1 - input2\n",
        "        dist_sq = torch.sum(torch.pow(diff, 2), 1)\n",
        "        dist = torch.sqrt(dist_sq)\n",
        "        mdist = self.margin - dist\n",
        "        dist = torch.clamp(mdist, min=0.0)\n",
        "        loss = y * dist_sq + (1 - y) * torch.pow(dist, 2)\n",
        "        loss = torch.sum(loss) / 2.0 / input1.size()[0]\n",
        "        return loss"
      ],
      "metadata": {
        "id": "c2_HzaSxouPx"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LFWDataset(Dataset):\n",
        "\n",
        "    def __init__(self, root_dir, path_file_dir, transform=None, random_aug=False):\n",
        "        self.root_dir = root_dir\n",
        "        path_file = open(path_file_dir, 'r')\n",
        "        data = []\n",
        "        for line in path_file:\n",
        "            line = line.strip()\n",
        "            img1, img2, label = line.split(' ')\n",
        "            label = int(label)\n",
        "            data.append((img1, img2, label))\n",
        "        self.data = data\n",
        "        self.transform = transform\n",
        "        self.random_aug = random_aug\n",
        "        self.random_aug_prob = 0.7\n",
        "        path_file.close()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img1, img2, label = self.data[idx]\n",
        "        img1_file = Image.open(os.path.join(self.root_dir, img1))\n",
        "        img2_file = Image.open(os.path.join(self.root_dir, img2))\n",
        "        if self.random_aug:\n",
        "            img1_file = self.random_augmentation(img1_file, self.random_aug_prob)\n",
        "            img2_file = self.random_augmentation(img2_file, self.random_aug_prob)\n",
        "\n",
        "        if self.transform:\n",
        "            img1_file = self.transform(img1_file)\n",
        "            img2_file = self.transform(img2_file)\n",
        "        return (img1_file, img2_file, label)\n",
        "\n",
        "    def random_augmentation(self, img, prob):\n",
        "        def rotate(img):\n",
        "            degree = random.randrange(-30, 30)\n",
        "            return img.rotate(degree)\n",
        "        def flip(img):\n",
        "            return img.transpose(Image.FLIP_LEFT_RIGHT)\n",
        "        def translate(img):\n",
        "            d_x = random.randrange(-10, 10)\n",
        "            d_y = random.randrange(-10, 10)\n",
        "            img = np.array(img)\n",
        "            mat = np.float32([[1, 0, d_x], [0, 1, d_y]])\n",
        "            num_rows, num_cols = img.shape[:2]\n",
        "            img = cv2.warpAffine(img, mat, (num_cols, num_rows))\n",
        "            return Image.fromarray(np.uint8(img))\n",
        "        def scale(img):\n",
        "            scale = 0.7 + 0.6 * random.random()\n",
        "            img = np.array(img)\n",
        "            mat = np.float32([[scale, 0, 0], [0, scale, 0]])\n",
        "            num_rows, num_cols = img.shape[:2]\n",
        "            img = cv2.warpAffine(img, mat, (num_cols, num_rows))\n",
        "            return Image.fromarray(np.uint8(img))\n",
        "\n",
        "        if random.random() > prob:\n",
        "            return img\n",
        "\n",
        "        transform_ops = [rotate, flip, translate, scale]\n",
        "        op_len = random.randrange(1, len(transform_ops) + 1)\n",
        "        ops = random.sample(transform_ops, op_len)\n",
        "        for op in ops:\n",
        "            img = op(img)\n",
        "        return img\n"
      ],
      "metadata": {
        "id": "z86GLa5xouTG"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Flatten(nn.Module):\n",
        "\n",
        "    def forward(self, input):\n",
        "        return input.view(input.size(0), -1)"
      ],
      "metadata": {
        "id": "ak6K1vOhT1Ab"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SiameseNetwork(nn.Module):\n",
        "\n",
        "    def __init__(self, contra_loss=False):\n",
        "        super(SiameseNetwork, self).__init__()\n",
        "\n",
        "        self.contra_loss = contra_loss\n",
        "\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=5, padding=2, stride=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=5, padding=2, stride=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1, stride=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            nn.Conv2d(256, 512, kernel_size=3, padding=1, stride=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm2d(512),\n",
        "\n",
        "            Flatten(),\n",
        "            nn.Linear(131072, 1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm2d(1024)\n",
        "        )\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(2048, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward_once(self, x):\n",
        "        output = self.cnn(x)\n",
        "        return output\n",
        "\n",
        "    def forward(self, input1, input2):\n",
        "        output1 = self.forward_once(input1)\n",
        "        output2 = self.forward_once(input2)\n",
        "        if self.contra_loss:\n",
        "            return output1, output2\n",
        "        else:\n",
        "            output = torch.cat((output1, output2), 1)\n",
        "            output = self.fc(output)\n",
        "            return output"
      ],
      "metadata": {
        "id": "tTL5GcQEd2lL"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def threashold_sigmoid(t):\n",
        "    \"\"\"prob > 0.5 --> 1 else 0\"\"\"\n",
        "    threashold = t.clone()\n",
        "    threashold.data.fill_(0.5)\n",
        "    return (t > threashold).float()"
      ],
      "metadata": {
        "id": "C1xVTXvFd2ne"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def threashold_contrastive_loss(input1, input2, m):\n",
        "    \"\"\"dist < m --> 1 else 0\"\"\"\n",
        "    diff = input1 - input2\n",
        "    dist_sq = torch.sum(torch.pow(diff, 2), 1)\n",
        "    dist = torch.sqrt(dist_sq)\n",
        "    threashold = dist.clone()\n",
        "    threashold.data.fill_(m)\n",
        "    return (dist < threashold).float().view(-1, 1)\n"
      ],
      "metadata": {
        "id": "RrjQ3hkSd2sL"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cur_time():\n",
        "    fmt = '%Y-%m-%d %H:%M:%S %Z%z'\n",
        "    eastern = timezone('US/Eastern')\n",
        "    naive_dt = datetime.now()\n",
        "    loc_dt = datetime.now(eastern)\n",
        "    return loc_dt.strftime(fmt).replace(' ', '_')\n"
      ],
      "metadata": {
        "id": "mYl_gR2xeL_e"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_against_data(args, label, dataset, siamese_net):\n",
        "    # Training accuracy\n",
        "    siamese_net.eval()  # Change model to 'eval' mode (BN uses moving mean/var).\n",
        "    correct = 0.0\n",
        "    total = 0.0\n",
        "    for img1_set, img2_set, labels in dataset:\n",
        "        labels = labels.view(-1, 1).float()\n",
        "        if args.cuda:\n",
        "            img1_set = img1_set.cuda()\n",
        "            img2_set = img2_set.cuda()\n",
        "            labels = labels.cuda()\n",
        "        img1_set = Variable(img1_set)\n",
        "        img2_set = Variable(img2_set)\n",
        "        labels = Variable(labels)\n",
        "\n",
        "        if args.contra_loss:\n",
        "            output1, output2 = siamese_net(img1_set, img2_set)\n",
        "            output_labels = threashold_contrastive_loss(output1, output2, args.margin)\n",
        "        else:\n",
        "            output_labels_prob = siamese_net(img1_set, img2_set)\n",
        "            output_labels = threashold_sigmoid(output_labels_prob)\n",
        "\n",
        "        if args.cuda:\n",
        "            output_labels = output_labels.cuda()\n",
        "        total += labels.size(0)\n",
        "        correct += (output_labels == labels).sum().data[0]\n",
        "\n",
        "    print('Accuracy of the model on the {} {} images: {} %%'.format(total, label, (100 * correct / total)))\n"
      ],
      "metadata": {
        "id": "mHdtGzPHemme"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(args):\n",
        "    default_transform = transforms.Compose([\n",
        "        transforms.Resize(128),  # Changed from Scale to Resize\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "    train_dataset = LFWDataset('./lfw', './train.txt', default_transform, args.randaug)\n",
        "    print(\"Loaded {} training data.\".format(len(train_dataset)))\n",
        "\n",
        "    # Data Loader (Input Pipeline)\n",
        "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                             batch_size=BATCH_SIZE,\n",
        "                                             shuffle=True)\n",
        "\n",
        "    siamese_net = SiameseNetwork(args.contra_loss)\n",
        "    if args.cuda:\n",
        "        siamese_net = siamese_net.cuda()\n",
        "\n",
        "    # Loss and Optimizer\n",
        "    if args.contra_loss:\n",
        "        criterion = ContrastiveLoss(margin=args.margin)\n",
        "    else:\n",
        "        criterion = nn.BCELoss()\n",
        "\n",
        "    optimizer = torch.optim.Adam(siamese_net.parameters())\n",
        "\n",
        "    # Train the Model\n",
        "    num_epochs = args.epoch\n",
        "    for epoch in range(num_epochs):\n",
        "        for i, (img1_set, img2_set, labels) in enumerate(train_loader):\n",
        "            if args.cuda:\n",
        "                img1_set = img1_set.cuda()\n",
        "                img2_set = img2_set.cuda()\n",
        "                labels = labels.cuda()\n",
        "\n",
        "            img1_set = Variable(img1_set)\n",
        "            img2_set = Variable(img2_set)\n",
        "            labels = Variable(labels.view(-1, 1).float())\n",
        "\n",
        "            # Forward + Backward + Optimize\n",
        "            optimizer.zero_grad()\n",
        "            if args.contra_loss:\n",
        "                output1, output2 = siamese_net(img1_set, img2_set)\n",
        "                loss = criterion(output1, output2, labels)\n",
        "            else:\n",
        "                output_labels_prob = siamese_net(img1_set, img2_set)\n",
        "                loss = criterion(output_labels_prob, labels)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        print('Epoch [%d/%d], Loss: %.4f' % (epoch+1, num_epochs, loss.item()))\n",
        "\n",
        "    # Training accuracy\n",
        "    test_against_data(args, 'training', train_loader, siamese_net)\n",
        "\n",
        "    # Save the Trained Model\n",
        "    model_file_name = \"{}_{}\".format(cur_time(), args.model_file)\n",
        "    torch.save(siamese_net.state_dict(), model_file_name)\n",
        "    print(\"Saved model at {}\".format(model_file_name))\n",
        "    return siamese_net"
      ],
      "metadata": {
        "id": "oH04IxIreMDD"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(args, siamese_net=None):\n",
        "    if not siamese_net:\n",
        "        saved_model = torch.load(args.model_file)\n",
        "        siamese_net = SiameseNetwork(args.contra_loss)\n",
        "        siamese_net.load_state_dict(saved_model)\n",
        "\n",
        "    if args.cuda:\n",
        "        siamese_net = siamese_net.cuda()\n",
        "\n",
        "    default_transform = transforms.Compose([\n",
        "        transforms.Scale(128),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "    test_dataset = LFWDataset('./lfw', './test.txt', default_transform)\n",
        "    print(\"Loaded {} test data.\".format(len(test_dataset)))\n",
        "\n",
        "    test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                              batch_size=BATCH_SIZE,\n",
        "                                              shuffle=False)\n",
        "\n",
        "    test_against_data(args, \"testing\", test_loader, siamese_net)\n"
      ],
      "metadata": {
        "id": "tBOIzC-9eMFx"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    arg_parser = argparse.ArgumentParser()\n",
        "    arg_parser.add_argument(\"action\", nargs='?', choices=['train', 'test', 'train_test'], default='train_test')\n",
        "    arg_parser.add_argument(\"model_file\", nargs='?', help=\"model file path\", default='siamese.pkl')\n",
        "    arg_parser.add_argument(\"-e\", \"--epoch\", type=int, help=\"training epochs\", default=1)\n",
        "    arg_parser.add_argument(\"-m\", \"--margin\", type=float, help=\"training epochs\", default=1.0)\n",
        "    arg_parser.add_argument(\"-c\", \"--cuda\", action='store_true', default=False)\n",
        "    arg_parser.add_argument(\"-r\", \"--randaug\", action='store_true', default=False)\n",
        "    arg_parser.add_argument(\"-cl\", \"--contra_loss\", action='store_true', default=False)\n",
        "\n",
        "    # For Colab/Jupyter, use empty list for args\n",
        "    args = arg_parser.parse_args([]) if 'google.colab' in str(get_ipython()) else arg_parser.parse_args()\n",
        "\n",
        "    print(\"Invoke {} with args {}\".format(args.action, args))\n",
        "    if args.action == \"train\":\n",
        "        train(args)\n",
        "    elif args.action == \"test\":\n",
        "        test(args)\n",
        "    elif args.action == 'train_test':\n",
        "        siamese_net = train(args)\n",
        "        test(args, siamese_net)"
      ],
      "metadata": {
        "id": "fzwAN9S2eMHG"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    class Args:\n",
        "        action = 'train_test'\n",
        "        model_file = 'siamese.pkl'\n",
        "        epoch = 10\n",
        "        margin = 1.0\n",
        "        cuda = torch.cuda.is_available()\n",
        "        randaug = False\n",
        "        contra_loss = False\n",
        "\n",
        "    args = Args()\n",
        "    main()"
      ],
      "metadata": {
        "id": "xiJ24Mhud2tz",
        "outputId": "ec5c7779-5eb8-480f-b0fd-c1472086a0fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Invoke train_test with args Namespace(action='train_test', model_file='siamese.pkl', epoch=1, margin=1.0, cuda=False, randaug=False, contra_loss=False)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: './train.txt'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-105-de45dc2d9ba2>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mArgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-104-3d99c1597d5f>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train_test'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0msiamese_net\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msiamese_net\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-102-5585c58b0139>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     ])\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLFWDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./lfw'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'./train.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_transform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandaug\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loaded {} training data.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-90-4a1ccf683ebc>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root_dir, path_file_dir, transform, random_aug)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_file_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_aug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroot_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mpath_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_file_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpath_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './train.txt'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Dcs4QCZjd2v5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3U05idQdd2ys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WbysDF-Od3Aq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, test_triplets):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for triplet in test_triplets:\n",
        "            a, p, n = load_triplet_images(triplet)\n",
        "            a = torch.tensor(a).unsqueeze(0).unsqueeze(0).to(device)\n",
        "            p = torch.tensor(p).unsqueeze(0).unsqueeze(0).to(device)\n",
        "            n = torch.tensor(n).unsqueeze(0).unsqueeze(0).to(device)\n",
        "\n",
        "            out_a, out_p = model.forward_once(a), model.forward_once(p)\n",
        "            out_n = model.forward_once(n)\n",
        "\n",
        "            d_ap = F.pairwise_distance(out_a, out_p)\n",
        "            d_an = F.pairwise_distance(out_a, out_n)\n",
        "\n",
        "            if d_ap.item() < d_an.item():\n",
        "                correct += 1\n",
        "            total += 1\n",
        "\n",
        "    print(f\"Accuracy on test set: {correct / total:.2f}\")\n"
      ],
      "metadata": {
        "id": "Xt-h10kqouVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model on the test triplets\n",
        "evaluate_model(model, test_triplets)"
      ],
      "metadata": {
        "id": "cuIgyx1ERk4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'siamese_signature_model.pth')\n",
        "\n",
        "# To load later\n",
        "# model.load_state_dict(torch.load('siamese_signature_model.pth'))\n",
        "# model.eval()\n"
      ],
      "metadata": {
        "id": "_AxePUUmouXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_signature_pair(img_path1, img_path2, model, threshold=1.5):\n",
        "    model.eval()\n",
        "    img1, img2 = load_triplet_images((img_path1, img_path2, img_path2))[:2]  # ignore negative\n",
        "\n",
        "    img1 = torch.tensor(img1).unsqueeze(0).unsqueeze(0).to(device)\n",
        "    img2 = torch.tensor(img2).unsqueeze(0).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        out1 = model.forward_once(img1)\n",
        "        out2 = model.forward_once(img2)\n",
        "\n",
        "    distance = F.pairwise_distance(out1, out2).item()\n",
        "    print(f\"Distance: {distance:.4f}\")\n",
        "    return distance < threshold  # True if similar\n"
      ],
      "metadata": {
        "id": "YLU0DlhOousF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example real vs. real (should return True if genuine match)\n",
        "img_path1 = 'iti/Computer_Vision/Day01/Siamese/personA/Test/personA_29.png'\n",
        "img_path2 = 'iti/Computer_Vision/Day01/Siamese/personA/Test/personA_13.png'\n",
        "\n",
        "# Example real vs. forged (should return False if forged)\n",
        "img_path3 = 'iti/Computer_Vision/Day01/Siamese/personA/Test/personA_29.png'\n",
        "img_path4 = 'iti/Computer_Vision/Day01/Siamese/personA/Test/personA_33.png'\n",
        "\n",
        "# Test genuine match\n",
        "is_match = test_signature_pair(img_path1, img_path2, model)\n",
        "print(\"Match (real vs. real):\", is_match)\n",
        "\n",
        "# Test forged case\n",
        "is_forged = test_signature_pair(img_path3, img_path4, model)\n",
        "print(\"Match (real vs. forged):\", is_forged)"
      ],
      "metadata": {
        "id": "yUjdinFtouu3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}