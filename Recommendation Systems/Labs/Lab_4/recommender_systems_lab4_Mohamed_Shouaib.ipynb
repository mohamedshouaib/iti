{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ ITI \\space AI-Pro: \\space Intake \\space 45 $$\n",
    "$$ Recommender \\space Systems $$\n",
    "$$ Lab \\space no. \\space 4 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check if GPU is available and set device accordingly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: NVIDIA GeForce MX130\n",
      "CUDA Version: 12.4\n",
      "PyTorch Version: 2.6.0+cu124\n",
      "cuDNN Enabled: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")  \n",
    "    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")  \n",
    "    print(\"Using CPU\")\n",
    "\n",
    "print(f\"CUDA Version: {torch.version.cuda}\")\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"cuDNN Enabled: {torch.backends.cudnn.enabled}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Tensors - The Fundamental Data Structure in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor_from_list:\n",
      " tensor([1, 2, 3, 4, 5])\n",
      "\n",
      "tensor_from_numpy:\n",
      " tensor([1, 2, 3, 4, 5])\n",
      "\n",
      "tensor_float32:\n",
      " tensor([1., 2., 3., 4., 5.])\n",
      "tensor_float64:\n",
      " tensor([1., 2., 3., 4., 5.], dtype=torch.float64)\n",
      "\n",
      "zeros_tensor:\n",
      " tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "random_tensor:\n",
      " tensor([[0.0676, 0.8340, 0.3412, 0.6605],\n",
      "        [0.6245, 0.8877, 0.2366, 0.0531],\n",
      "        [0.5842, 0.0786, 0.2252, 0.5496]])\n",
      "identity_matrix:\n",
      " tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]])\n",
      "range_tensor:\n",
      " tensor([ 0,  2,  4,  6,  8, 10])\n",
      "linspace_tensor:\n",
      " tensor([0.0000, 0.2500, 0.5000, 0.7500, 1.0000])\n"
     ]
    }
   ],
   "source": [
    "# From Python lists\n",
    "tensor_from_list = torch.tensor([1, 2, 3, 4, 5])\n",
    "print(f'tensor_from_list:\\n {tensor_from_list}')\n",
    "\n",
    "# From NumPy arrays\n",
    "np_array = np.array([1, 2, 3, 4, 5])\n",
    "tensor_from_numpy = torch.from_numpy(np_array)\n",
    "print(f'\\ntensor_from_numpy:\\n {tensor_from_numpy}')\n",
    "\n",
    "# Tensor with specific data type (float32, float64)\n",
    "tensor_float32 = torch.tensor([1, 2, 3, 4, 5], dtype=torch.float32)\n",
    "print(f'\\ntensor_float32:\\n {tensor_float32}')\n",
    "tensor_float64 = torch.tensor([1, 2, 3, 4, 5], dtype=torch.float64)\n",
    "print(f'tensor_float64:\\n {tensor_float64}')\n",
    "\n",
    "# Creating tensors with specific shapes\n",
    "zeros_tensor = torch.zeros((3, 4))    \n",
    "print(f'\\nzeros_tensor:\\n {zeros_tensor}')\n",
    "random_tensor = torch.rand((3, 4))  \n",
    "print(f'random_tensor:\\n {random_tensor}')\n",
    "identity_matrix = torch.eye(3)  \n",
    "print(f'identity_matrix:\\n {identity_matrix}')\n",
    "range_tensor = torch.arange(0, 11, 2)  \n",
    "print(f'range_tensor:\\n {range_tensor}')\n",
    "linspace_tensor = torch.linspace(0, 1, steps=5)  \n",
    "print(f'linspace_tensor:\\n {linspace_tensor}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor operations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum_tensor:\n",
      "tensor([[ 6,  8],\n",
      "        [10, 12]])\n",
      "\n",
      "mul_tensor:\n",
      "tensor([[ 5, 12],\n",
      "        [21, 32]])\n",
      "\n",
      "matmul_tensor:\n",
      "tensor([[19, 22],\n",
      "        [43, 50]])\n",
      "\n",
      "\n",
      "reshaped_tensor:\n",
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6]])\n",
      "\n",
      "flattened_tensor:\n",
      "tensor([1, 2, 3, 4, 5, 6])\n",
      "\n",
      "\n",
      "device:\n",
      "cuda\n",
      "\n",
      "tensor_gpu:\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Adding, multiplication\n",
    "tensor_a = torch.tensor([[1, 2], [3, 4]])\n",
    "tensor_b = torch.tensor([[5, 6], [7, 8]])\n",
    "\n",
    "sum_tensor = tensor_a + tensor_b\n",
    "print(f'sum_tensor:\\n{sum_tensor}')\n",
    "\n",
    "mul_tensor = tensor_a * tensor_b\n",
    "print(f'\\nmul_tensor:\\n{mul_tensor}')\n",
    "\n",
    "matmul_tensor = torch.matmul(tensor_a, tensor_b)\n",
    "print(f'\\nmatmul_tensor:\\n{matmul_tensor}')\n",
    "\n",
    "# Reshaping tensors\n",
    "tensor = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "reshaped_tensor = tensor.reshape(3, 2)\n",
    "print(f'\\n\\nreshaped_tensor:\\n{reshaped_tensor}')\n",
    "\n",
    "flattened_tensor = tensor.view(-1)\n",
    "print(f'\\nflattened_tensor:\\n{flattened_tensor}')\n",
    "\n",
    "# Moving tensors to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'\\n\\ndevice:\\n{device}')\n",
    "tensor_gpu = tensor.to(device)\n",
    "print(f'\\ntensor_gpu:\\n{tensor_gpu}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Autograd - Automatic Differentiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:\n",
      "2.0\n",
      "\n",
      "\n",
      "y(x**2):\n",
      "4.0\n",
      "\n",
      "Gradient of x (dy/dx):\n",
      "4.0\n",
      "\n",
      "\n",
      "y(x**3):\n",
      "8.0\n",
      "\n",
      "Gradient after first backward:\n",
      "12.0\n",
      "\n",
      "y(x**4):\n",
      "16.0\n",
      "\n",
      "Gradient after second backward (accumulated,without zeroing):\n",
      "44.0\n",
      "\n",
      "Gradient after zeroing:\n",
      "4.0\n"
     ]
    }
   ],
   "source": [
    "# Creating tensors with gradient tracking\n",
    "x = torch.tensor(2.0, requires_grad=True)\n",
    "print(f'x:\\n{x}')\n",
    "\n",
    "# Computing gradients\n",
    "y = x**2\n",
    "print(f'\\n\\ny(x**2):\\n{y}')\n",
    "y.backward()\n",
    "print(f'\\nGradient of x (dy/dx):\\n{x.grad}')\n",
    "\n",
    "# Example of gradient accumulation and zeroing\n",
    "x.grad = None  \n",
    "y = x**3  \n",
    "y.backward()\n",
    "print(f'\\n\\ny(x**3):\\n{y}')\n",
    "print(f'\\nGradient after first backward:\\n{x.grad}')\n",
    "# Gradient will accumulate if we don't zero it\n",
    "y = x**4 \n",
    "print(f'\\ny(x**4):\\n{y}') \n",
    "y.backward()\n",
    "print(f'\\nGradient after second backward (accumulated,without zeroing):\\n{x.grad}')\n",
    "\n",
    "# Zero the gradient and compute again\n",
    "x.grad.zero_()\n",
    "y = x**2  \n",
    "y.backward()\n",
    "print(f'\\nGradient after zeroing:\\n{x.grad}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Neural Networks with nn.Module\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SimpleNN class defined successfully!\n",
      "\n",
      "Model Architecture:\n",
      "SimpleNN(\n",
      "  (fc1): Linear(in_features=3, out_features=5, bias=True)\n",
      "  (fc2): Linear(in_features=5, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      ")\n",
      "\n",
      "Random input tensor:\n",
      "tensor([[0.7308, 0.3964, 0.9817]])\n",
      "\n",
      "Output after forward pass:\n",
      "tensor([[-0.2799]], grad_fn=<AddmmBackward0>)\n",
      "\n",
      "Parameter - fc1.weight:\n",
      "Parameter containing:\n",
      "tensor([[ 0.2715, -0.4179, -0.3174],\n",
      "        [ 0.5139, -0.0734,  0.2406],\n",
      "        [-0.0659, -0.3530,  0.3819],\n",
      "        [ 0.3367,  0.5041, -0.1733],\n",
      "        [ 0.5425, -0.4054, -0.3593]], requires_grad=True)\n",
      "Parameter - fc1.bias:\n",
      "Parameter containing:\n",
      "tensor([ 0.5190, -0.5702,  0.3484, -0.4992,  0.5218], requires_grad=True)\n",
      "Parameter - fc2.weight:\n",
      "Parameter containing:\n",
      "tensor([[ 0.2617, -0.4249, -0.4001, -0.0035, -0.2430]], requires_grad=True)\n",
      "Parameter - fc2.bias:\n",
      "Parameter containing:\n",
      "tensor([-0.0249], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Define a simple neural network\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN,self).__init__()\n",
    "        self.fc1 = nn.Linear(3,5)\n",
    "        self.fc2 = nn.Linear(5,1)\n",
    "        self.relu = nn.ReLU()\n",
    "    def forward(self,x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "print(f'\\nSimpleNN class defined successfully!')\n",
    "\n",
    "# Create a model instance\n",
    "model = SimpleNN()\n",
    "print(f'\\nModel Architecture:\\n{model}')\n",
    "\n",
    "# Random input\n",
    "input_tensor = torch.rand(1,3)\n",
    "print(f'\\nRandom input tensor:\\n{input_tensor}')\n",
    "\n",
    "# Forward pass\n",
    "output = model(input_tensor)\n",
    "print(f'\\nOutput after forward pass:\\n{output}\\n')\n",
    "\n",
    "# Access model parameters, print them\n",
    "# Print model parameters\n",
    "for name, param in model.named_parameters():\n",
    "    print(f'Parameter - {name}:\\n{param}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Loss Functions and Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x (input data):\n",
      "tensor([[0.0936],\n",
      "        [0.9975],\n",
      "        [0.5761],\n",
      "        [0.4847],\n",
      "        [0.2713]])\n",
      "y (target labels):\n",
      "tensor([[2.3987],\n",
      "        [4.9545],\n",
      "        [3.8583],\n",
      "        [3.5637],\n",
      "        [2.8048]])\n",
      "Model Architecture:\n",
      "LinearRegressionModel(\n",
      "  (fc1): Linear(in_features=1, out_features=1, bias=True)\n",
      ")\n",
      "Epoch 1, Loss: 6.5592\n",
      "Epoch 2, Loss: 6.2418\n",
      "Epoch 3, Loss: 5.9402\n",
      "Epoch 4, Loss: 5.6536\n",
      "Epoch 5, Loss: 5.3811\n",
      "Epoch 6, Loss: 5.1222\n",
      "Epoch 7, Loss: 4.8761\n",
      "Epoch 8, Loss: 4.6423\n",
      "Epoch 9, Loss: 4.4200\n",
      "Epoch 10, Loss: 4.2088\n",
      "Epoch 11, Loss: 4.0080\n",
      "Epoch 12, Loss: 3.8172\n",
      "Epoch 13, Loss: 3.6359\n",
      "Epoch 14, Loss: 3.4636\n",
      "Epoch 15, Loss: 3.2998\n",
      "Epoch 16, Loss: 3.1441\n",
      "Epoch 17, Loss: 2.9961\n",
      "Epoch 18, Loss: 2.8555\n",
      "Epoch 19, Loss: 2.7218\n",
      "Epoch 20, Loss: 2.5948\n",
      "Epoch 21, Loss: 2.4741\n",
      "Epoch 22, Loss: 2.3593\n",
      "Epoch 23, Loss: 2.2502\n",
      "Epoch 24, Loss: 2.1466\n",
      "Epoch 25, Loss: 2.0480\n",
      "Epoch 26, Loss: 1.9544\n",
      "Epoch 27, Loss: 1.8653\n",
      "Epoch 28, Loss: 1.7807\n",
      "Epoch 29, Loss: 1.7003\n",
      "Epoch 30, Loss: 1.6238\n",
      "Epoch 31, Loss: 1.5511\n",
      "Epoch 32, Loss: 1.4820\n",
      "Epoch 33, Loss: 1.4164\n",
      "Epoch 34, Loss: 1.3539\n",
      "Epoch 35, Loss: 1.2946\n",
      "Epoch 36, Loss: 1.2382\n",
      "Epoch 37, Loss: 1.1845\n",
      "Epoch 38, Loss: 1.1335\n",
      "Epoch 39, Loss: 1.0851\n",
      "Epoch 40, Loss: 1.0390\n",
      "Epoch 41, Loss: 0.9952\n",
      "Epoch 42, Loss: 0.9535\n",
      "Epoch 43, Loss: 0.9139\n",
      "Epoch 44, Loss: 0.8763\n",
      "Epoch 45, Loss: 0.8405\n",
      "Epoch 46, Loss: 0.8064\n",
      "Epoch 47, Loss: 0.7741\n",
      "Epoch 48, Loss: 0.7433\n",
      "Epoch 49, Loss: 0.7140\n",
      "Epoch 50, Loss: 0.6862\n",
      "Epoch 51, Loss: 0.6597\n",
      "Epoch 52, Loss: 0.6345\n",
      "Epoch 53, Loss: 0.6106\n",
      "Epoch 54, Loss: 0.5878\n",
      "Epoch 55, Loss: 0.5662\n",
      "Epoch 56, Loss: 0.5456\n",
      "Epoch 57, Loss: 0.5260\n",
      "Epoch 58, Loss: 0.5073\n",
      "Epoch 59, Loss: 0.4896\n",
      "Epoch 60, Loss: 0.4727\n",
      "Epoch 61, Loss: 0.4567\n",
      "Epoch 62, Loss: 0.4414\n",
      "Epoch 63, Loss: 0.4269\n",
      "Epoch 64, Loss: 0.4131\n",
      "Epoch 65, Loss: 0.3999\n",
      "Epoch 66, Loss: 0.3874\n",
      "Epoch 67, Loss: 0.3755\n",
      "Epoch 68, Loss: 0.3641\n",
      "Epoch 69, Loss: 0.3533\n",
      "Epoch 70, Loss: 0.3431\n",
      "Epoch 71, Loss: 0.3333\n",
      "Epoch 72, Loss: 0.3240\n",
      "Epoch 73, Loss: 0.3151\n",
      "Epoch 74, Loss: 0.3066\n",
      "Epoch 75, Loss: 0.2986\n",
      "Epoch 76, Loss: 0.2909\n",
      "Epoch 77, Loss: 0.2836\n",
      "Epoch 78, Loss: 0.2767\n",
      "Epoch 79, Loss: 0.2700\n",
      "Epoch 80, Loss: 0.2637\n",
      "Epoch 81, Loss: 0.2577\n",
      "Epoch 82, Loss: 0.2519\n",
      "Epoch 83, Loss: 0.2465\n",
      "Epoch 84, Loss: 0.2413\n",
      "Epoch 85, Loss: 0.2363\n",
      "Epoch 86, Loss: 0.2315\n",
      "Epoch 87, Loss: 0.2270\n",
      "Epoch 88, Loss: 0.2227\n",
      "Epoch 89, Loss: 0.2186\n",
      "Epoch 90, Loss: 0.2146\n",
      "Epoch 91, Loss: 0.2109\n",
      "Epoch 92, Loss: 0.2073\n",
      "Epoch 93, Loss: 0.2039\n",
      "Epoch 94, Loss: 0.2006\n",
      "Epoch 95, Loss: 0.1975\n",
      "Epoch 96, Loss: 0.1945\n",
      "Epoch 97, Loss: 0.1916\n",
      "Epoch 98, Loss: 0.1889\n",
      "Epoch 99, Loss: 0.1863\n",
      "Epoch 100, Loss: 0.1838\n",
      "Epoch 101, Loss: 0.1814\n",
      "Epoch 102, Loss: 0.1791\n",
      "Epoch 103, Loss: 0.1769\n",
      "Epoch 104, Loss: 0.1748\n",
      "Epoch 105, Loss: 0.1728\n",
      "Epoch 106, Loss: 0.1709\n",
      "Epoch 107, Loss: 0.1690\n",
      "Epoch 108, Loss: 0.1672\n",
      "Epoch 109, Loss: 0.1655\n",
      "Epoch 110, Loss: 0.1639\n",
      "Epoch 111, Loss: 0.1623\n",
      "Epoch 112, Loss: 0.1608\n",
      "Epoch 113, Loss: 0.1594\n",
      "Epoch 114, Loss: 0.1580\n",
      "Epoch 115, Loss: 0.1566\n",
      "Epoch 116, Loss: 0.1554\n",
      "Epoch 117, Loss: 0.1541\n",
      "Epoch 118, Loss: 0.1529\n",
      "Epoch 119, Loss: 0.1518\n",
      "Epoch 120, Loss: 0.1507\n",
      "Epoch 121, Loss: 0.1496\n",
      "Epoch 122, Loss: 0.1485\n",
      "Epoch 123, Loss: 0.1475\n",
      "Epoch 124, Loss: 0.1466\n",
      "Epoch 125, Loss: 0.1456\n",
      "Epoch 126, Loss: 0.1447\n",
      "Epoch 127, Loss: 0.1439\n",
      "Epoch 128, Loss: 0.1430\n",
      "Epoch 129, Loss: 0.1422\n",
      "Epoch 130, Loss: 0.1414\n",
      "Epoch 131, Loss: 0.1406\n",
      "Epoch 132, Loss: 0.1399\n",
      "Epoch 133, Loss: 0.1392\n",
      "Epoch 134, Loss: 0.1385\n",
      "Epoch 135, Loss: 0.1378\n",
      "Epoch 136, Loss: 0.1371\n",
      "Epoch 137, Loss: 0.1365\n",
      "Epoch 138, Loss: 0.1358\n",
      "Epoch 139, Loss: 0.1352\n",
      "Epoch 140, Loss: 0.1346\n",
      "Epoch 141, Loss: 0.1340\n",
      "Epoch 142, Loss: 0.1335\n",
      "Epoch 143, Loss: 0.1329\n",
      "Epoch 144, Loss: 0.1324\n",
      "Epoch 145, Loss: 0.1318\n",
      "Epoch 146, Loss: 0.1313\n",
      "Epoch 147, Loss: 0.1308\n",
      "Epoch 148, Loss: 0.1303\n",
      "Epoch 149, Loss: 0.1298\n",
      "Epoch 150, Loss: 0.1293\n",
      "Epoch 151, Loss: 0.1289\n",
      "Epoch 152, Loss: 0.1284\n",
      "Epoch 153, Loss: 0.1280\n",
      "Epoch 154, Loss: 0.1275\n",
      "Epoch 155, Loss: 0.1271\n",
      "Epoch 156, Loss: 0.1266\n",
      "Epoch 157, Loss: 0.1262\n",
      "Epoch 158, Loss: 0.1258\n",
      "Epoch 159, Loss: 0.1254\n",
      "Epoch 160, Loss: 0.1250\n",
      "Epoch 161, Loss: 0.1246\n",
      "Epoch 162, Loss: 0.1242\n",
      "Epoch 163, Loss: 0.1238\n",
      "Epoch 164, Loss: 0.1234\n",
      "Epoch 165, Loss: 0.1230\n",
      "Epoch 166, Loss: 0.1227\n",
      "Epoch 167, Loss: 0.1223\n",
      "Epoch 168, Loss: 0.1219\n",
      "Epoch 169, Loss: 0.1216\n",
      "Epoch 170, Loss: 0.1212\n",
      "Epoch 171, Loss: 0.1209\n",
      "Epoch 172, Loss: 0.1205\n",
      "Epoch 173, Loss: 0.1202\n",
      "Epoch 174, Loss: 0.1198\n",
      "Epoch 175, Loss: 0.1195\n",
      "Epoch 176, Loss: 0.1192\n",
      "Epoch 177, Loss: 0.1188\n",
      "Epoch 178, Loss: 0.1185\n",
      "Epoch 179, Loss: 0.1182\n",
      "Epoch 180, Loss: 0.1178\n",
      "Epoch 181, Loss: 0.1175\n",
      "Epoch 182, Loss: 0.1172\n",
      "Epoch 183, Loss: 0.1169\n",
      "Epoch 184, Loss: 0.1166\n",
      "Epoch 185, Loss: 0.1162\n",
      "Epoch 186, Loss: 0.1159\n",
      "Epoch 187, Loss: 0.1156\n",
      "Epoch 188, Loss: 0.1153\n",
      "Epoch 189, Loss: 0.1150\n",
      "Epoch 190, Loss: 0.1147\n",
      "Epoch 191, Loss: 0.1144\n",
      "Epoch 192, Loss: 0.1141\n",
      "Epoch 193, Loss: 0.1138\n",
      "Epoch 194, Loss: 0.1135\n",
      "Epoch 195, Loss: 0.1132\n",
      "Epoch 196, Loss: 0.1129\n",
      "Epoch 197, Loss: 0.1126\n",
      "Epoch 198, Loss: 0.1124\n",
      "Epoch 199, Loss: 0.1121\n",
      "Epoch 200, Loss: 0.1118\n",
      "Epoch 201, Loss: 0.1115\n",
      "Epoch 202, Loss: 0.1112\n",
      "Epoch 203, Loss: 0.1109\n",
      "Epoch 204, Loss: 0.1106\n",
      "Epoch 205, Loss: 0.1104\n",
      "Epoch 206, Loss: 0.1101\n",
      "Epoch 207, Loss: 0.1098\n",
      "Epoch 208, Loss: 0.1095\n",
      "Epoch 209, Loss: 0.1093\n",
      "Epoch 210, Loss: 0.1090\n",
      "Epoch 211, Loss: 0.1087\n",
      "Epoch 212, Loss: 0.1084\n",
      "Epoch 213, Loss: 0.1082\n",
      "Epoch 214, Loss: 0.1079\n",
      "Epoch 215, Loss: 0.1076\n",
      "Epoch 216, Loss: 0.1074\n",
      "Epoch 217, Loss: 0.1071\n",
      "Epoch 218, Loss: 0.1068\n",
      "Epoch 219, Loss: 0.1066\n",
      "Epoch 220, Loss: 0.1063\n",
      "Epoch 221, Loss: 0.1060\n",
      "Epoch 222, Loss: 0.1058\n",
      "Epoch 223, Loss: 0.1055\n",
      "Epoch 224, Loss: 0.1053\n",
      "Epoch 225, Loss: 0.1050\n",
      "Epoch 226, Loss: 0.1047\n",
      "Epoch 227, Loss: 0.1045\n",
      "Epoch 228, Loss: 0.1042\n",
      "Epoch 229, Loss: 0.1040\n",
      "Epoch 230, Loss: 0.1037\n",
      "Epoch 231, Loss: 0.1035\n",
      "Epoch 232, Loss: 0.1032\n",
      "Epoch 233, Loss: 0.1029\n",
      "Epoch 234, Loss: 0.1027\n",
      "Epoch 235, Loss: 0.1024\n",
      "Epoch 236, Loss: 0.1022\n",
      "Epoch 237, Loss: 0.1019\n",
      "Epoch 238, Loss: 0.1017\n",
      "Epoch 239, Loss: 0.1014\n",
      "Epoch 240, Loss: 0.1012\n",
      "Epoch 241, Loss: 0.1009\n",
      "Epoch 242, Loss: 0.1007\n",
      "Epoch 243, Loss: 0.1005\n",
      "Epoch 244, Loss: 0.1002\n",
      "Epoch 245, Loss: 0.1000\n",
      "Epoch 246, Loss: 0.0997\n",
      "Epoch 247, Loss: 0.0995\n",
      "Epoch 248, Loss: 0.0992\n",
      "Epoch 249, Loss: 0.0990\n",
      "Epoch 250, Loss: 0.0988\n",
      "Epoch 251, Loss: 0.0985\n",
      "Epoch 252, Loss: 0.0983\n",
      "Epoch 253, Loss: 0.0980\n",
      "Epoch 254, Loss: 0.0978\n",
      "Epoch 255, Loss: 0.0976\n",
      "Epoch 256, Loss: 0.0973\n",
      "Epoch 257, Loss: 0.0971\n",
      "Epoch 258, Loss: 0.0969\n",
      "Epoch 259, Loss: 0.0966\n",
      "Epoch 260, Loss: 0.0964\n",
      "Epoch 261, Loss: 0.0962\n",
      "Epoch 262, Loss: 0.0959\n",
      "Epoch 263, Loss: 0.0957\n",
      "Epoch 264, Loss: 0.0955\n",
      "Epoch 265, Loss: 0.0952\n",
      "Epoch 266, Loss: 0.0950\n",
      "Epoch 267, Loss: 0.0948\n",
      "Epoch 268, Loss: 0.0945\n",
      "Epoch 269, Loss: 0.0943\n",
      "Epoch 270, Loss: 0.0941\n",
      "Epoch 271, Loss: 0.0939\n",
      "Epoch 272, Loss: 0.0936\n",
      "Epoch 273, Loss: 0.0934\n",
      "Epoch 274, Loss: 0.0932\n",
      "Epoch 275, Loss: 0.0929\n",
      "Epoch 276, Loss: 0.0927\n",
      "Epoch 277, Loss: 0.0925\n",
      "Epoch 278, Loss: 0.0923\n",
      "Epoch 279, Loss: 0.0921\n",
      "Epoch 280, Loss: 0.0918\n",
      "Epoch 281, Loss: 0.0916\n",
      "Epoch 282, Loss: 0.0914\n",
      "Epoch 283, Loss: 0.0912\n",
      "Epoch 284, Loss: 0.0910\n",
      "Epoch 285, Loss: 0.0907\n",
      "Epoch 286, Loss: 0.0905\n",
      "Epoch 287, Loss: 0.0903\n",
      "Epoch 288, Loss: 0.0901\n",
      "Epoch 289, Loss: 0.0899\n",
      "Epoch 290, Loss: 0.0896\n",
      "Epoch 291, Loss: 0.0894\n",
      "Epoch 292, Loss: 0.0892\n",
      "Epoch 293, Loss: 0.0890\n",
      "Epoch 294, Loss: 0.0888\n",
      "Epoch 295, Loss: 0.0886\n",
      "Epoch 296, Loss: 0.0884\n",
      "Epoch 297, Loss: 0.0882\n",
      "Epoch 298, Loss: 0.0879\n",
      "Epoch 299, Loss: 0.0877\n",
      "Epoch 300, Loss: 0.0875\n",
      "Epoch 301, Loss: 0.0873\n",
      "Epoch 302, Loss: 0.0871\n",
      "Epoch 303, Loss: 0.0869\n",
      "Epoch 304, Loss: 0.0867\n",
      "Epoch 305, Loss: 0.0865\n",
      "Epoch 306, Loss: 0.0863\n",
      "Epoch 307, Loss: 0.0861\n",
      "Epoch 308, Loss: 0.0859\n",
      "Epoch 309, Loss: 0.0857\n",
      "Epoch 310, Loss: 0.0855\n",
      "Epoch 311, Loss: 0.0852\n",
      "Epoch 312, Loss: 0.0850\n",
      "Epoch 313, Loss: 0.0848\n",
      "Epoch 314, Loss: 0.0846\n",
      "Epoch 315, Loss: 0.0844\n",
      "Epoch 316, Loss: 0.0842\n",
      "Epoch 317, Loss: 0.0840\n",
      "Epoch 318, Loss: 0.0838\n",
      "Epoch 319, Loss: 0.0836\n",
      "Epoch 320, Loss: 0.0834\n",
      "Epoch 321, Loss: 0.0832\n",
      "Epoch 322, Loss: 0.0830\n",
      "Epoch 323, Loss: 0.0828\n",
      "Epoch 324, Loss: 0.0826\n",
      "Epoch 325, Loss: 0.0824\n",
      "Epoch 326, Loss: 0.0823\n",
      "Epoch 327, Loss: 0.0821\n",
      "Epoch 328, Loss: 0.0819\n",
      "Epoch 329, Loss: 0.0817\n",
      "Epoch 330, Loss: 0.0815\n",
      "Epoch 331, Loss: 0.0813\n",
      "Epoch 332, Loss: 0.0811\n",
      "Epoch 333, Loss: 0.0809\n",
      "Epoch 334, Loss: 0.0807\n",
      "Epoch 335, Loss: 0.0805\n",
      "Epoch 336, Loss: 0.0803\n",
      "Epoch 337, Loss: 0.0801\n",
      "Epoch 338, Loss: 0.0799\n",
      "Epoch 339, Loss: 0.0797\n",
      "Epoch 340, Loss: 0.0796\n",
      "Epoch 341, Loss: 0.0794\n",
      "Epoch 342, Loss: 0.0792\n",
      "Epoch 343, Loss: 0.0790\n",
      "Epoch 344, Loss: 0.0788\n",
      "Epoch 345, Loss: 0.0786\n",
      "Epoch 346, Loss: 0.0784\n",
      "Epoch 347, Loss: 0.0782\n",
      "Epoch 348, Loss: 0.0781\n",
      "Epoch 349, Loss: 0.0779\n",
      "Epoch 350, Loss: 0.0777\n",
      "Epoch 351, Loss: 0.0775\n",
      "Epoch 352, Loss: 0.0773\n",
      "Epoch 353, Loss: 0.0771\n",
      "Epoch 354, Loss: 0.0770\n",
      "Epoch 355, Loss: 0.0768\n",
      "Epoch 356, Loss: 0.0766\n",
      "Epoch 357, Loss: 0.0764\n",
      "Epoch 358, Loss: 0.0762\n",
      "Epoch 359, Loss: 0.0761\n",
      "Epoch 360, Loss: 0.0759\n",
      "Epoch 361, Loss: 0.0757\n",
      "Epoch 362, Loss: 0.0755\n",
      "Epoch 363, Loss: 0.0753\n",
      "Epoch 364, Loss: 0.0752\n",
      "Epoch 365, Loss: 0.0750\n",
      "Epoch 366, Loss: 0.0748\n",
      "Epoch 367, Loss: 0.0746\n",
      "Epoch 368, Loss: 0.0745\n",
      "Epoch 369, Loss: 0.0743\n",
      "Epoch 370, Loss: 0.0741\n",
      "Epoch 371, Loss: 0.0739\n",
      "Epoch 372, Loss: 0.0738\n",
      "Epoch 373, Loss: 0.0736\n",
      "Epoch 374, Loss: 0.0734\n",
      "Epoch 375, Loss: 0.0732\n",
      "Epoch 376, Loss: 0.0731\n",
      "Epoch 377, Loss: 0.0729\n",
      "Epoch 378, Loss: 0.0727\n",
      "Epoch 379, Loss: 0.0726\n",
      "Epoch 380, Loss: 0.0724\n",
      "Epoch 381, Loss: 0.0722\n",
      "Epoch 382, Loss: 0.0721\n",
      "Epoch 383, Loss: 0.0719\n",
      "Epoch 384, Loss: 0.0717\n",
      "Epoch 385, Loss: 0.0716\n",
      "Epoch 386, Loss: 0.0714\n",
      "Epoch 387, Loss: 0.0712\n",
      "Epoch 388, Loss: 0.0711\n",
      "Epoch 389, Loss: 0.0709\n",
      "Epoch 390, Loss: 0.0707\n",
      "Epoch 391, Loss: 0.0706\n",
      "Epoch 392, Loss: 0.0704\n",
      "Epoch 393, Loss: 0.0702\n",
      "Epoch 394, Loss: 0.0701\n",
      "Epoch 395, Loss: 0.0699\n",
      "Epoch 396, Loss: 0.0697\n",
      "Epoch 397, Loss: 0.0696\n",
      "Epoch 398, Loss: 0.0694\n",
      "Epoch 399, Loss: 0.0692\n",
      "Epoch 400, Loss: 0.0691\n",
      "Epoch 401, Loss: 0.0689\n",
      "Epoch 402, Loss: 0.0688\n",
      "Epoch 403, Loss: 0.0686\n",
      "Epoch 404, Loss: 0.0684\n",
      "Epoch 405, Loss: 0.0683\n",
      "Epoch 406, Loss: 0.0681\n",
      "Epoch 407, Loss: 0.0680\n",
      "Epoch 408, Loss: 0.0678\n",
      "Epoch 409, Loss: 0.0677\n",
      "Epoch 410, Loss: 0.0675\n",
      "Epoch 411, Loss: 0.0673\n",
      "Epoch 412, Loss: 0.0672\n",
      "Epoch 413, Loss: 0.0670\n",
      "Epoch 414, Loss: 0.0669\n",
      "Epoch 415, Loss: 0.0667\n",
      "Epoch 416, Loss: 0.0666\n",
      "Epoch 417, Loss: 0.0664\n",
      "Epoch 418, Loss: 0.0663\n",
      "Epoch 419, Loss: 0.0661\n",
      "Epoch 420, Loss: 0.0659\n",
      "Epoch 421, Loss: 0.0658\n",
      "Epoch 422, Loss: 0.0656\n",
      "Epoch 423, Loss: 0.0655\n",
      "Epoch 424, Loss: 0.0653\n",
      "Epoch 425, Loss: 0.0652\n",
      "Epoch 426, Loss: 0.0650\n",
      "Epoch 427, Loss: 0.0649\n",
      "Epoch 428, Loss: 0.0647\n",
      "Epoch 429, Loss: 0.0646\n",
      "Epoch 430, Loss: 0.0644\n",
      "Epoch 431, Loss: 0.0643\n",
      "Epoch 432, Loss: 0.0641\n",
      "Epoch 433, Loss: 0.0640\n",
      "Epoch 434, Loss: 0.0638\n",
      "Epoch 435, Loss: 0.0637\n",
      "Epoch 436, Loss: 0.0636\n",
      "Epoch 437, Loss: 0.0634\n",
      "Epoch 438, Loss: 0.0633\n",
      "Epoch 439, Loss: 0.0631\n",
      "Epoch 440, Loss: 0.0630\n",
      "Epoch 441, Loss: 0.0628\n",
      "Epoch 442, Loss: 0.0627\n",
      "Epoch 443, Loss: 0.0625\n",
      "Epoch 444, Loss: 0.0624\n",
      "Epoch 445, Loss: 0.0623\n",
      "Epoch 446, Loss: 0.0621\n",
      "Epoch 447, Loss: 0.0620\n",
      "Epoch 448, Loss: 0.0618\n",
      "Epoch 449, Loss: 0.0617\n",
      "Epoch 450, Loss: 0.0615\n",
      "Epoch 451, Loss: 0.0614\n",
      "Epoch 452, Loss: 0.0613\n",
      "Epoch 453, Loss: 0.0611\n",
      "Epoch 454, Loss: 0.0610\n",
      "Epoch 455, Loss: 0.0608\n",
      "Epoch 456, Loss: 0.0607\n",
      "Epoch 457, Loss: 0.0606\n",
      "Epoch 458, Loss: 0.0604\n",
      "Epoch 459, Loss: 0.0603\n",
      "Epoch 460, Loss: 0.0602\n",
      "Epoch 461, Loss: 0.0600\n",
      "Epoch 462, Loss: 0.0599\n",
      "Epoch 463, Loss: 0.0597\n",
      "Epoch 464, Loss: 0.0596\n",
      "Epoch 465, Loss: 0.0595\n",
      "Epoch 466, Loss: 0.0593\n",
      "Epoch 467, Loss: 0.0592\n",
      "Epoch 468, Loss: 0.0591\n",
      "Epoch 469, Loss: 0.0589\n",
      "Epoch 470, Loss: 0.0588\n",
      "Epoch 471, Loss: 0.0587\n",
      "Epoch 472, Loss: 0.0585\n",
      "Epoch 473, Loss: 0.0584\n",
      "Epoch 474, Loss: 0.0583\n",
      "Epoch 475, Loss: 0.0581\n",
      "Epoch 476, Loss: 0.0580\n",
      "Epoch 477, Loss: 0.0579\n",
      "Epoch 478, Loss: 0.0577\n",
      "Epoch 479, Loss: 0.0576\n",
      "Epoch 480, Loss: 0.0575\n",
      "Epoch 481, Loss: 0.0573\n",
      "Epoch 482, Loss: 0.0572\n",
      "Epoch 483, Loss: 0.0571\n",
      "Epoch 484, Loss: 0.0570\n",
      "Epoch 485, Loss: 0.0568\n",
      "Epoch 486, Loss: 0.0567\n",
      "Epoch 487, Loss: 0.0566\n",
      "Epoch 488, Loss: 0.0564\n",
      "Epoch 489, Loss: 0.0563\n",
      "Epoch 490, Loss: 0.0562\n",
      "Epoch 491, Loss: 0.0561\n",
      "Epoch 492, Loss: 0.0559\n",
      "Epoch 493, Loss: 0.0558\n",
      "Epoch 494, Loss: 0.0557\n",
      "Epoch 495, Loss: 0.0556\n",
      "Epoch 496, Loss: 0.0554\n",
      "Epoch 497, Loss: 0.0553\n",
      "Epoch 498, Loss: 0.0552\n",
      "Epoch 499, Loss: 0.0551\n",
      "Epoch 500, Loss: 0.0549\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x738d77edb830>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create some dummy data\n",
    "x = torch.rand(100,1)\n",
    "y = 3 * x + 2 + 0.1 * torch.randn(100, 1)\n",
    "print(f'x (input data):\\n{x[:5]}')\n",
    "print(f'y (target labels):\\n{y[:5]}')\n",
    "\n",
    "# Create a model\n",
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearRegressionModel,self).__init__()\n",
    "        self.fc1 = nn.Linear(1,1)\n",
    "    def forward(self,x):\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "model = LinearRegressionModel()\n",
    "print(f'Model Architecture:\\n{model}')\n",
    "\n",
    "# Define loss function and optimizer\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=0.01)\n",
    "\n",
    "# Train for 5 epochs\n",
    "epochs = 500\n",
    "losses = []\n",
    "for epoch in range(epochs):\n",
    "    y_pred = model(x)\n",
    "    loss = loss_fn(y_pred,y)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    losses.append(loss.detach())\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(f'Epoch {epoch+1}, Loss: {loss.item():.4f}')\n",
    "\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Datasets and DataLoaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformations defined successfully!\n",
      "\n",
      "MNIST dataset loaded successfully!\n",
      "DataLoaders created successfully!\n",
      "Function to display images defined successfully!\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert images to tensors\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Normalize to range [-1, 1]\n",
    "])\n",
    "print(f'Transformations defined successfully!\\n')\n",
    "\n",
    "\n",
    "# Load MNIST dataset\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "print(f'MNIST dataset loaded successfully!')\n",
    "\n",
    "# Create DataLoaders\n",
    "from torch.utils.data import DataLoader\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)\n",
    "print(f'DataLoaders created successfully!')\n",
    "\n",
    "# Visualize a batch of data\n",
    "# Function to display images\n",
    "def show_images(images, labels, num_images=16):\n",
    "    images = images[:num_images]  # Select first 'num_images'\n",
    "    labels = labels[:num_images]\n",
    "    \n",
    "    fig, axes = plt.subplots(4, 4, figsize=(8, 8))  # Create a 4x4 grid\n",
    "    fig.suptitle(\"MNIST Sample Batch\", fontsize=16)\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        img = images[i].squeeze().numpy()  # Remove extra dimensions\n",
    "        ax.imshow(img, cmap='gray')  # Display image in grayscale\n",
    "        ax.set_title(f'Label: {labels[i].item()}')\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "print(f'Function to display images defined successfully!')\n",
    "\n",
    "# Display a batch of images\n",
    "# Get one batch of images\n",
    "images, labels = next(iter(train_loader))\n",
    "\n",
    "# Show batch of images\n",
    "show_images(images, labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Convolutional Neural Networks (CNNs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN Model class defined successfully!\n",
      "Model Architecture:\n",
      "SimpleCNN(\n",
      "  (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=1568, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define a CNN model\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "\n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, padding=1)  # 1 input channel (grayscale), 16 filters\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)  # 32 filters\n",
    "\n",
    "        # Pooling layer\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(32 * 7 * 7, 128)  # Flattened size (32 filters * 7x7)\n",
    "        self.fc2 = nn.Linear(128, 10)  # 10 output classes (digits 0-9)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # Conv -> ReLU -> Pool\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # Conv -> ReLU -> Pool\n",
    "        x = torch.flatten(x, start_dim=1)  # Flatten before FC layers\n",
    "        x = F.relu(self.fc1(x))  # FC layer with ReLU\n",
    "        x = self.fc2(x)  # Output layer\n",
    "        return x\n",
    "\n",
    "print(f'CNN Model class defined successfully!')\n",
    "\n",
    "# Create a CNN model\n",
    "model = SimpleCNN()\n",
    "print(f'Model Architecture:\\n{model}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Training a CNN on MNIST\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loss function and optimizer initialized!\n",
      "Training function defined successfully!\n",
      "Epoch [1/5], Loss: 0.2064\n",
      "Epoch [2/5], Loss: 0.0539\n",
      "Epoch [3/5], Loss: 0.0369\n",
      "Epoch [4/5], Loss: 0.0297\n",
      "Epoch [5/5], Loss: 0.0234\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# Move model to device (GPU if available)\n",
    "# Check if GPU is available and # Move model to device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Using device: {device}')\n",
    "model.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "print(f'Loss function and optimizer initialized!')\n",
    "\n",
    "# Train function\n",
    "def train(model, train_loader, loss_fn, optimizer, epochs=5):\n",
    "    model.train()  # Set model to training mode\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)  # Move to GPU if available\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()  # Zero gradients\n",
    "            loss.backward()  # Compute gradients\n",
    "            optimizer.step()  # Update weights\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}')\n",
    "    \n",
    "    print('Training complete!')\n",
    "\n",
    "print(f'Training function defined successfully!')\n",
    "train(model, train_loader, loss_fn, optimizer, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Evaluating the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation function defined successfully!\n",
      "Test Accuracy: 98.96%\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model, test_loader):\n",
    "    model.eval()  \n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)  # Move to GPU if available\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)  # Get the class with highest probability\n",
    "            \n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Test Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "print(f'Evaluation function defined successfully!')\n",
    "evaluate(model, test_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Saving and Loading Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model (parameters) saved successfully!\n",
      "Full model saved successfully!\n",
      "\n",
      "Model (parameters) loaded successfully!\n",
      "Full model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Save model\n",
    "torch.save(model.state_dict(), 'cnn_model.pth')\n",
    "print('\\nModel (parameters) saved successfully!')\n",
    "torch.save(model, 'cnn_model_full.pth')\n",
    "print('Full model saved successfully!')\n",
    "\n",
    "# Load model\n",
    "model1 = SimpleCNN()\n",
    "model1.load_state_dict(torch.load('cnn_model.pth'))\n",
    "model1.to(device)\n",
    "print('\\nModel (parameters) loaded successfully!')\n",
    "\n",
    "model2 = SimpleCNN()\n",
    "model2 = torch.load('cnn_model_full.pth', weights_only=False)\n",
    "model2.to(device)\n",
    "print('Full model loaded successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Transfer Learning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shouaib/anaconda3/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/shouaib/anaconda3/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Model:\n",
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
      ")\n",
      "Modified Model for MNIST:\n",
      "ResNet(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define a new model based on a pre-trained network\n",
    "model = torchvision.models.resnet18(pretrained=True)   # Load pre-trained ResNet18\n",
    "print(f'Original Model:\\n{model}')\n",
    "\n",
    "# Create transfer learning model\n",
    "num_classes = 10\n",
    "model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "                                        # Replace with new FC layer \n",
    "                                        # Since ResNet18 was trained on ImageNet (1000 classes), \n",
    "                                        # we replace the last fully connected (FC) layer with one suited \n",
    "                                        # for MNIST (10 classes).\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "print(f'Modified Model for MNIST:\\n{model}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss function and optimizer defined!\n",
      "Training function for transfer learning defined!\n",
      "Epoch [1/5], Loss: 1.4985\n",
      "Epoch [2/5], Loss: 1.3555\n",
      "Epoch [3/5], Loss: 1.3240\n",
      "Epoch [4/5], Loss: 1.3131\n",
      "Epoch [5/5], Loss: 1.3124\n",
      "Transfer learning training complete!\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define optimizer (only train the modified classifier layer)\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n",
    "\n",
    "print(f'Loss function and optimizer defined!')\n",
    "\n",
    "def train_transfer_learning(model, train_loader, loss_fn, optimizer, epochs=5):\n",
    "    model.train()  # Set model to training mode\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)  # Move to GPU if available\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}')\n",
    "    \n",
    "    print('Transfer learning training complete!')\n",
    "\n",
    "print(f'Training function for transfer learning defined!')\n",
    "train_transfer_learning(model, train_loader, loss_fn, optimizer, epochs=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Advanced Techniques: Learning Rate Scheduler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Rate Scheduler Defined!\n",
      "Training function with scheduler defined!\n",
      "Epoch [1/10], Loss: 1.3083, LR: 0.001000\n",
      "Epoch [2/10], Loss: 1.3030, LR: 0.001000\n",
      "Epoch [3/10], Loss: 1.3061, LR: 0.001000\n",
      "Epoch [4/10], Loss: 1.3018, LR: 0.001000\n",
      "Epoch [5/10], Loss: 1.3025, LR: 0.000500\n",
      "Epoch [6/10], Loss: 1.2798, LR: 0.000500\n",
      "Epoch [7/10], Loss: 1.2805, LR: 0.000500\n",
      "Epoch [8/10], Loss: 1.2785, LR: 0.000500\n",
      "Epoch [9/10], Loss: 1.2688, LR: 0.000500\n",
      "Epoch [10/10], Loss: 1.2724, LR: 0.000250\n",
      "Training with Learning Rate Scheduler Complete!\n"
     ]
    }
   ],
   "source": [
    "# Define a learning rate scheduler\n",
    "optimizer = torch.optim.Adam(model.fc.parameters(), lr=0.001)\n",
    "# Define learning rate scheduler (decrease LR by 0.1 every 5 epochs)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "print(f'Learning Rate Scheduler Defined!')\n",
    "\n",
    "# Simulate training for 10 epochs\n",
    "def train_with_scheduler(model, train_loader, loss_fn, optimizer, scheduler, epochs=10):\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        # Step the scheduler\n",
    "        scheduler.step()\n",
    "\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}, LR: {current_lr:.6f}')\n",
    "    \n",
    "    print('Training with Learning Rate Scheduler Complete!')\n",
    "\n",
    "print(f'Training function with scheduler defined!')\n",
    "train_with_scheduler(model, train_loader, loss_fn, optimizer, scheduler, epochs=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Custom Datasets\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Custom Dataset:\n",
      "Dataset size: 100\n",
      "\n",
      "\n",
      "torch.Size([16, 3, 32, 32]) torch.Size([16])\n",
      "torch.Size([16, 3, 32, 32]) torch.Size([16])\n",
      "torch.Size([16, 3, 32, 32]) torch.Size([16])\n",
      "torch.Size([16, 3, 32, 32]) torch.Size([16])\n",
      "torch.Size([16, 3, 32, 32]) torch.Size([16])\n",
      "torch.Size([16, 3, 32, 32]) torch.Size([16])\n",
      "torch.Size([4, 3, 32, 32]) torch.Size([4])\n",
      "\n",
      "Batch size: torch.Size([16, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, labels, transform=None):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)  # Apply transformation if specified\n",
    "\n",
    "        return sample, label\n",
    "\n",
    "# Example usage:\n",
    "data = torch.randn(100, 3, 32, 32)  # Example 100 images (3x32x32)\n",
    "labels = torch.randint(0, 10, (100,))  # Example labels (0-9 classes)\n",
    "\n",
    "dataset = CustomDataset(data, labels)\n",
    "\n",
    "# Access an item\n",
    "sample, label = dataset[0]\n",
    "print(\"\\nCustom Dataset:\")\n",
    "print(f\"Dataset size: {len(dataset)}\\n\\n\")\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "for batch in dataloader:\n",
    "    images, labels = batch\n",
    "    print(images.shape, labels.shape)\n",
    "\n",
    "print(f\"\\nBatch size: {next(iter(dataloader))[0].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------\n",
    "\n",
    "$$ Wish \\space you \\space all \\space the \\space best \\space  $$\n",
    "$$ Mahmoud \\space Shawqi $$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
